-----------
adapters\__init__.py

-----------

-----------
adapters\alpaca_adapter.py
# CHANGES:
# - Added get_clock() method that returns the raw Alpaca clock object (is_open, next_close, next_open).
#   This exposes next_close so main.py can compute time-until-close without a second API call.
#   get_market_open() is unchanged and still used everywhere else.

import logging
import os
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

import alpaca_trade_api as tradeapi

logger = logging.getLogger("tradebot")


class AlpacaAdapter:
    """Thin adapter around Alpaca REST API, configured purely by env vars
    APCA_API_BASE_URL / APCA_API_KEY_ID / APCA_API_SECRET_KEY."""

    def __init__(self, env_mode: str):
        self.env_mode = env_mode
        base_url = os.getenv("APCA_API_BASE_URL", "https://paper-api.alpaca.markets")
        key_id = os.getenv("APCA_API_KEY_ID")
        secret_key = os.getenv("APCA_API_SECRET_KEY")
        if not key_id or not secret_key:
            raise ValueError("APCA_API_KEY_ID and APCA_API_SECRET_KEY must be set")
        self.rest = tradeapi.REST(
            key_id=key_id,
            secret_key=secret_key,
            base_url=base_url,
            api_version="v2",
        )

    # --- Account / positions ---

    def get_account(self) -> Any:
        return self.rest.get_account()

    def list_positions(self) -> List[Any]:
        return list(self.rest.list_positions()) or []

    def get_position(self, symbol: str) -> Optional[Any]:
        try:
            return self.rest.get_position(symbol)
        except Exception:
            return None

    # --- Market status ---

    def get_clock(self) -> Optional[Any]:
        """Return the raw Alpaca clock object (is_open, next_close, next_open).
        Returns None on error so callers must guard against None."""
        try:
            return self.rest.get_clock()
        except Exception as e:
            logger.warning(f"get_clock error: {e}")
            return None

    def get_market_open(self) -> bool:
        """Returns True if the US equity market is currently open, False otherwise.
        Uses Alpaca's v2/clock endpoint."""
        try:
            clock = self.rest.get_clock()
            return bool(clock.is_open)
        except Exception:
            return False

    # --- Market data ---

    def get_last_quote(self, symbol: str) -> float:
        """Get a close/last price proxy via recent bars, fallback to latest trade."""
        end = datetime.utcnow()
        start = end - timedelta(minutes=60)
        try:
            bars = self.rest.get_bars(
                symbol, "5Min", start.isoformat() + "Z", end.isoformat() + "Z",
            )
        except Exception as e:
            print(f"get_bars error for {symbol}: {e}")
            bars = []
        if not bars:
            last = self.rest.get_latest_trade(symbol)
            return float(last.price)
        bar = bars[-1]
        close_price = getattr(bar, "c", None)
        if close_price is None:
            close_price = bar.c
        return float(close_price)

    def get_recent_bars(
        self,
        symbol: str,
        timeframe: str = "5Min",
        lookback_bars: int = 30,
    ) -> List[Any]:
        """Fetch up to lookback_bars recent bars for symbol.

        Fix 7: The start timestamp is now anchored 3 calendar days back
        (previously lookback_bars * 5 * 30 minutes).  This ensures the request
        window covers weekends, holidays, and pre/post-market gaps so the API
        always has enough trading bars to fill the limit.  The Alpaca API
        ``limit`` parameter caps the returned count at lookback_bars regardless
        of how wide the window is.  A WARNING is emitted if fewer bars than
        requested are returned, so under-fill is never silent downstream
        (RSI fallback to 50.0 etc.).
        """
        end = datetime.utcnow()
        # 3-day window survives any weekend / holiday combination.
        start = end - timedelta(days=3)
        try:
            bars = self.rest.get_bars(
                symbol,
                timeframe,
                start.isoformat() + "Z",
                end.isoformat() + "Z",
                limit=lookback_bars,
            )
        except Exception as e:
            logger.warning(
                f"get_recent_bars error for {symbol} "
                f"(timeframe={timeframe}, lookback={lookback_bars}): {e}"
            )
            bars = []
        result = list(bars) or []
        # Fix 7: warn explicitly when under-filled so issues are visible in logs.
        if len(result) < lookback_bars:
            logger.warning(
                f"get_recent_bars {symbol}: requested {lookback_bars} bars, "
                f"received {len(result)} — signal quality may be degraded. "
                f"RSI/momentum may fall back to neutral defaults."
            )
        return result

    # --- News sentiment inputs ---

    def get_news(
        self,
        symbol: str,
        since: Optional[datetime] = None,
        limit: int = 20,
    ) -> List[Dict[str, str]]:
        try:
            kwargs: Dict[str, Any] = {"symbol": symbol, "limit": limit}
            if since is not None:
                kwargs["start"] = since.isoformat() + "Z"
            raw_items = self.rest.get_news(**kwargs)
        except Exception as e:
            print(f"get_news error for {symbol}: {e}")
            return []
        out: List[Dict[str, str]] = []
        for n in raw_items:
            headline = getattr(n, "headline", "") or ""
            summary = getattr(n, "summary", "") or ""
            out.append({"headline": headline, "summary": summary})
        return out

    # --- Orders ---

    def submit_market_order(
        self,
        symbol: str,
        qty: float,
        side: str,
        time_in_force: str = "day",
    ) -> Any:
        return self.rest.submit_order(
            symbol=symbol,
            side=side,
            type="market",
            qty=qty,
            time_in_force=time_in_force,
        )

    def submit_bracket_order(
        self,
        symbol: str,
        qty: float,
        side: str,
        stop_price: float,
        take_profit_price: float,
        time_in_force: str = "day",
    ) -> Any:
        """Submit an entry market order with an attached TP limit + fixed stop-loss
        as a single Alpaca bracket order (order_class='bracket').

        Alpaca manages the two exit legs as an internal OCO pair, so there is
        never a qty-reservation conflict between TP and stop orders.

        Direction is inferred automatically from ``side``:
        - buy  bracket: TP limit above entry, stop below entry.
        - sell bracket: TP limit below entry, stop above entry.

        Both prices are computed correctly by SignalEngine._decide_side_and_bands().
        """
        return self.rest.submit_order(
            symbol=symbol,
            side=side,
            type="market",
            qty=qty,
            time_in_force=time_in_force,
            order_class="bracket",
            take_profit={"limit_price": str(round(take_profit_price, 2))},
            stop_loss={"stop_price": str(round(stop_price, 2))},
        )

    def submit_take_profit_limit_order(
        self,
        symbol: str,
        qty: float,
        side: str,
        limit_price: float,
        time_in_force: str = "day",
    ) -> Any:
        return self.rest.submit_order(
            symbol=symbol,
            side=side,
            type="limit",
            qty=qty,
            limit_price=limit_price,
            time_in_force=time_in_force,
        )

    def submit_stop_order(
        self,
        symbol: str,
        qty: float,
        side: str,
        stop_price: float,
        time_in_force: str = "day",
    ) -> Any:
        """Submit a plain stop-market order.  Used as the fallback single-exit
        path when only enable_trailing_stop is True (no TP configured).
        stop_price is the ATR-based level computed by SignalEngine."""
        return self.rest.submit_order(
            symbol=symbol,
            side=side,
            type="stop",
            qty=qty,
            stop_price=stop_price,
            time_in_force=time_in_force,
        )

    def submit_trailing_stop_order(
        self,
        symbol: str,
        qty: float,
        side: str,
        trail_percent: float,
        time_in_force: str = "day",
    ) -> Any:
        return self.rest.submit_order(
            symbol=symbol,
            side=side,
            type="trailing_stop",
            qty=qty,
            trail_percent=trail_percent,
            time_in_force=time_in_force,
        )

    def cancel_order(self, order_id: str) -> None:
        self.rest.cancel_order(order_id)

    def cancel_all_orders(self) -> None:
        self.rest.cancel_all_orders()

    def close_all_positions(self) -> None:
        self.rest.close_all_positions()

    def list_orders(self, status: str = "open") -> List[Any]:
        return list(self.rest.list_orders(status=status)) or []

-----------

-----------
ai_client.py
# CHANGES:
# Fix M6 — In scorenews(), added type-coercion for the sentiment field before
#   the membership check.  After sentiment = result.get("sentiment", 0), we now
#   apply: try: sentiment = int(round(float(sentiment))) except (TypeError,
#   ValueError): sentiment = 0.  This handles model responses that return the
#   value as a float string (e.g. "-1.0") or a bare float, which would
#   previously fall through the `if sentiment not in (-2,-1,0,1)` guard and
#   silently become 0.  No variable renames.

# aiclient.py
import json
import os
import requests


class NewsReasoner:
    """
    Uses Perplexity's Chat Completions API (OpenAI-compatible with the sonar model)
    to score short-term news sentiment.

    Returns a dict with keys:
        - sentiment: int in {-2, -1, 0, 1}
        - confidence: float in [0, 1]
        - explanation: str
    """

    def __init__(self) -> None:
        # Read directly from environment variables
        self.apiurl = os.getenv("AI_API_URL", "https://api.perplexity.ai/chat/completions")
        self.apikey = os.getenv("AI_API_KEY")
        if not self.apikey:
            raise RuntimeError("AI_API_KEY is not set. Please export your Perplexity API key.")

    def scorenews(self, symbol: str, newsitems):
        """
        Input:
            symbol: string ticker, e.g. "AAPL"
            newsitems: list of dicts from Alpaca news API

        Output dict:
            - sentiment: -2, -1, 0, or 1
            - confidence: float 0-1
            - explanation: str
        """
        try:
            # No news -> neutral, low confidence
            if not newsitems:
                return {
                    "sentiment": 0,
                    "confidence": 0.0,
                    "explanation": "No recent news."
                }

            # Build compact headlines + summaries for up to 10 news items
            summaries = []
            for n in newsitems[:10]:
                title = n.get("headline") or n.get("title") or ""
                summary = n.get("summary") or ""
                text = f"{title} {summary}".strip()
                if not text:
                    continue
                summaries.append(text[:300])
            if not summaries:
                return {
                    "sentiment": 0,
                    "confidence": 0.0,
                    "explanation": "No usable news text."
                }

            userprompt = (
                f"You are a professional equity analyst.\n"
                f"Evaluate the SHORT-TERM (next few trading days) impact of the following news "
                f"on {symbol} stock.\n"
                f"Return a single JSON object with keys:\n"
                f'  sentiment: -2, -1, 0, or 1\n'
                f'    -2 for extremely unstable / utterly undesirable to trade now (e.g. chaotic, '
                f'        very high uncertainty, extreme event risk),\n'
                f'    -1 for clearly negative,\n'
                f'     0 for neutral or mixed,\n'
                f'     1 for clearly positive.\n'
                f'  confidence: a number between 0 and 1\n'
                f'  explanation: short textual explanation (1-3 sentences).\n\n'
                f"News:\n- " + "\n- ".join(summaries)
            )

            headers = {
                "Authorization": f"Bearer {self.apikey}",
                "Content-Type": "application/json",
            }
            payload = {
                "model": "sonar",
                "messages": [
                    {
                        "role": "system",
                        "content": (
                            "You are a precise financial sentiment classifier. "
                            "You only output strict JSON with the requested keys."
                        ),
                    },
                    {
                        "role": "user",
                        "content": userprompt,
                    },
                ],
                "temperature": 0.1,
                "max_tokens": 300,
            }

            resp = requests.post(self.apiurl, headers=headers, json=payload, timeout=30)
            if not resp.ok:
                # Log error and degrade gracefully to neutral sentiment
                print("Perplexity error", resp.status_code, resp.text)
                return {
                    "sentiment": 0,
                    "confidence": 0.0,
                    "explanation": "Error from AI API, treating sentiment as neutral.",
                }

            data = resp.json()
            rawcontent = data["choices"][0]["message"]["content"].strip()

            # Expect JSON, fallback to extracting JSON substring if needed
            try:
                result = json.loads(rawcontent)
            except json.JSONDecodeError:
                try:
                    start = rawcontent.index("{")
                    end = rawcontent.rindex("}") + 1
                    result = json.loads(rawcontent[start:end])
                except Exception:
                    return {
                        "sentiment": 0,
                        "confidence": 0.0,
                        "explanation": "Could not parse model output, treating as neutral.",
                    }

            sentiment = result.get("sentiment", 0)
            # Fix M6: coerce to int before membership check so float strings
            # like "-1.0" or bare floats from the model are handled correctly.
            try:
                sentiment = int(round(float(sentiment)))
            except (TypeError, ValueError):
                sentiment = 0
            # Normalize sentiment to allowed set {-2, -1, 0, 1}
            if sentiment not in (-2, -1, 0, 1):
                sentiment = 0

            try:
                confidence = float(result.get("confidence", 0.0))
            except (TypeError, ValueError):
                confidence = 0.0
            confidence = max(0.0, min(1.0, confidence))

            explanation = result.get("explanation", "")

            return {
                "sentiment": sentiment,
                "confidence": confidence,
                "explanation": explanation,
            }

        except Exception as e:
            # Normalize fields on any unexpected error
            print("scorenews error", e)
            return {
                "sentiment": 0,
                "confidence": 0.0,
                "explanation": "Exception in sentiment analysis, treating as neutral.",
            }

-----------

-----------
config\__init__.py

-----------

-----------
config\config.py
# CHANGES:
# FIX 7 — Added ema_crossover_norm_scale: float = 0.10 to TechnicalSignalConfig.
#   Previously _compute_simple_momentum_raw() divided raw EMA crossover by
#   momentum_norm_scale (0.05), causing saturation at ±1 for high-momentum
#   equities where the EMA spread exceeds 5%.  The new field widens the graded
#   range to ±10%.  Existing momentum_norm_scale (used by
#   _normalize_momentum_trend()) is unchanged.  New field carries a default so
#   backward compatibility with all existing configs is maintained.
#
# All prior changes (Fix L3, Change 2, Change 4) are preserved unchanged.

import os
import yaml
from pathlib import Path
from dataclasses import dataclass, asdict
from typing import Dict

ENV_MODE = os.getenv("APCA_API_ENV", "PAPER").upper()
if ENV_MODE not in ("PAPER", "LIVE"):
    raise ValueError(f"Invalid APCA_API_ENV={ENV_MODE}, expected PAPER or LIVE")

LIVE_TRADING_ENABLED = os.getenv("LIVE_TRADING_ENABLED", "false").lower() == "true"


@dataclass
class RiskLimits:
    max_risk_per_trade_pct: float = 0.03     # 3% of equity
    min_risk_per_trade_pct: float = 0.005    # 0.5% of equity
    gross_exposure_cap_pct: float = 0.90     # 90% of equity
    daily_loss_limit_pct: float = 0.04       # 4% of start-of-day equity
    max_drawdown_pct: float = 0.09           # 9% from high watermark
    max_open_positions: int = 15
    # Task 4: Half-Kelly position sizing is now the VALIDATED DEFAULT.
    # Set to False ONLY for emergency rollback to fixed-fractional sizing.
    # Override via environment config or load_config() — do not change this line
    # without re-running the Kelly calibration tests.
    enable_kelly_sizing: bool = True
    # Improvement A: percentile of the rolling vol history (maxlen=200) used as
    # the denominator when normalising volatility inside _kelly_fraction.
    # 0.50 = median; raise toward 0.75 to be less sensitive to vol spikes.
    kelly_vol_norm_percentile: float = 0.50
    # Improvement C: weight applied to the clamped sentiment score in the
    # log-odds blend for Kelly p.  Increasing this makes sentiment more
    # influential on position size.
    kelly_sentiment_weight: float = 0.08


@dataclass
class SentimentConfig:
    neutral_band: float = 0.1
    min_scale: float = 0.2
    max_scale: float = 1.3
    no_trade_negative_threshold: float = -0.4
    # --- Sentiment-exit thresholds ---
    # Hard exit: raw_discrete == -2 -> always close, no delta check (unchanged).
    #
    # Soft exit: fires when delta > soft_exit_delta_threshold AND
    #            confidence > exit_confidence_min.
    #            Catches partial deterioration (e.g. +0.7 -> 0.0, delta=0.70).
    soft_exit_delta_threshold: float = 0.6
    #
    # Strong exit: fires when delta > strong_exit_delta_threshold AND
    #              confidence > strong_exit_confidence_min.
    #              Lower confidence bar because a large delta is self-confirming.
    strong_exit_delta_threshold: float = 1.0
    strong_exit_confidence_min: float = 0.4
    #
    # Minimum model confidence for the soft exit tier.
    exit_confidence_min: float = 0.5
    #
    # Improvement E: exponent applied to confidence before multiplying by base.
    # gamma=1.0 -> linear (original behaviour); gamma=2.0 -> convex weighting
    # that rewards high-confidence scores more and down-weights low-confidence
    # ones.  Clamped to [1.0, 4.0] at runtime.
    confidence_gamma: float = 2.0
    #
    # Legacy alias kept for any downstream code that reads this field directly.
    # Points at the strong threshold so behaviour is unchanged if old code path
    # is ever re-activated.  Do not remove.
    @property
    def exit_sentiment_delta_threshold(self) -> float:
        return self.strong_exit_delta_threshold


@dataclass
class TechnicalSignalConfig:
    weight_momentum_trend: float = 0.5
    weight_mean_reversion: float = 0.3
    weight_price_action: float = 0.2
    long_threshold: float = 0.2
    short_threshold: float = -0.2
    momentum_norm_scale: float = 0.05
    ma_distance_norm_scale: float = 0.05
    rsi_overbought: float = 70.0
    rsi_oversold: float = 30.0
    breakout_lookback_bars: int = 20
    breakout_strength: float = 1.0
    base_stop_vol_mult: float = 1.5
    base_tp_vol_mult: float = 3.0
    max_tp_scale_from_signal: float = 1.3
    min_tp_scale_from_signal: float = 0.7
    # Improvement B: fraction of long_th / short_th that the cached sentiment
    # score is allowed to shift the entry threshold asymmetrically.
    # 0.25 means sentiment can tighten or widen each threshold by up to 25%.
    sentiment_th_scale: float = 0.25
    # Fix L3: explicit field so it is visible to introspection/serialisation
    # and can be overridden via config.  Previously accessed via getattr fallback.
    conflict_dampener_penalty: float = 0.6
    # FIX 7: normalisation scale for EMA crossover signal.
    # Wider than momentum_norm_scale (0.05) to prevent ±1 saturation for
    # high-momentum equities (NVDA, TSLA) where EMA spread can exceed 5%.
    # 0.10 allows a graded signal up to ±10% EMA divergence.
    ema_crossover_norm_scale: float = 0.10


@dataclass
class ExecutionConfig:
    enable_trailing_stop: bool = True
    trailing_stop_percent: float = 5.0   # 5% trailing distance
    enable_take_profit: bool = True
    exit_time_in_force: str = "day"
    entry_time_in_force: str = "day"
    post_entry_fill_timeout_sec: int = 15


@dataclass
class InstrumentMeta:
    symbol: str
    exchange: str
    lot_size: float
    fractional: bool
    shortable: bool
    marginable: bool
    trading_hours: str
    sector: str = "UNKNOWN"


@dataclass
class PortfolioConfig:
    enable_portfolio_veto: bool = False
    max_candidates_per_loop: int = 50
    # Fix 4: maximum positions allowed per sector in the selection loop.
    # Prevents the portfolio from being overweight in a single sector
    # (e.g. all 10 TECH symbols selected when only 3 are desired).
    max_positions_per_sector: int = 3


@dataclass
class BotConfig:
    env_mode: str
    live_trading_enabled: bool
    risk_limits: RiskLimits
    sentiment: SentimentConfig
    technical: TechnicalSignalConfig
    execution: ExecutionConfig
    instruments: Dict[str, InstrumentMeta]
    portfolio: PortfolioConfig


@dataclass
class AIConfig:
    api_url: str
    api_key: str


def _load_instrument_whitelist(path: Path) -> Dict[str, InstrumentMeta]:
    if not path.exists():
        raise FileNotFoundError(f"Instrument whitelist not found at {path}")
    with path.open("r") as f:
        data = yaml.safe_load(f) or {}
    instruments: Dict[str, InstrumentMeta] = {}
    for sym, meta in data.items():
        instruments[sym] = InstrumentMeta(
            symbol=sym,
            exchange=meta.get("exchange", "NYSE"),
            lot_size=float(meta.get("lot_size", 1)),
            fractional=bool(meta.get("fractional", False)),
            shortable=bool(meta.get("shortable", False)),
            marginable=bool(meta.get("marginable", False)),
            trading_hours=meta.get("trading_hours", "09:30-16:00"),
            sector=meta.get("sector", "UNKNOWN"),
        )
    return instruments


def load_config() -> BotConfig:
    base = Path(__file__).resolve().parents[1]
    wl_path = base / "config" / "instrument_whitelist.yaml"
    instruments = _load_instrument_whitelist(wl_path)

    risk = RiskLimits()
    sentiment = SentimentConfig()
    technical = TechnicalSignalConfig()
    execution = ExecutionConfig()
    portfolio = PortfolioConfig()

    cfg = BotConfig(
        env_mode=ENV_MODE,
        live_trading_enabled=LIVE_TRADING_ENABLED,
        risk_limits=risk,
        sentiment=sentiment,
        technical=technical,
        execution=execution,
        instruments=instruments,
        portfolio=portfolio,
    )
    return cfg


if __name__ == "__main__":
    cfg = load_config()
    print(asdict(cfg))

-----------

-----------
config\instrument_whitelist.yaml
# ── Active symbols (debugging set) ───────────────────────────────────────────

AAPL:
  exchange: NASDAQ
  lot_size: 1
  fractional: true
  shortable: true
  marginable: true
  trading_hours: "0930-1600"
  sector: TECH

# ── Disabled symbols — uncomment ALL lines of a block to re-enable ────────────


MSFT:
  exchange: NASDAQ
  lot_size: 1
  fractional: true
  shortable: true
  marginable: true
  trading_hours: "0930-1600"
  sector: TECH


GOOGL:
  exchange: NASDAQ
  lot_size: 1
  fractional: true
  shortable: true
  marginable: true
  trading_hours: "0930-1600"
  sector: TECH


AMZN:
  exchange: NASDAQ
  lot_size: 1
  fractional: true
  shortable: true
  marginable: true
  trading_hours: "0930-1600"
  sector: TECH


NVDA:
  exchange: NASDAQ
  lot_size: 1
  fractional: true
  shortable: true
  marginable: true
  trading_hours: "0930-1600"
  sector: TECH


META:
  exchange: NASDAQ
  lot_size: 1
  fractional: true
  shortable: true
  marginable: true
  trading_hours: "0930-1600"
  sector: TECH


TSLA:
  exchange: NASDAQ
  lot_size: 1
  fractional: true
  shortable: true
  marginable: true
  trading_hours: "0930-1600"
  sector: TECH


AMD:
  exchange: NASDAQ
  lot_size: 1
  fractional: true
  shortable: true
  marginable: true
  trading_hours: "0930-1600"
  sector: TECH

# DISABLED: MU
# MU:
#   exchange: NASDAQ
#   lot_size: 1
#   fractional: true
#   shortable: true
#   marginable: true
#   trading_hours: "0930-1600"
#   sector: TECH

# DISABLED: NFLX
# NFLX:
#   exchange: NASDAQ
#   lot_size: 1
#   fractional: true
#   shortable: true
#   marginable: true
#   trading_hours: "0930-1600"
#   sector: TECH

# DISABLED: SPY
# SPY:
#   exchange: NYSE
#   lot_size: 1
#   fractional: true
#   shortable: true
#   marginable: true
#   trading_hours: "0930-1600"
#   sector: ETF_INDEX

# DISABLED: QQQ
# QQQ:
#   exchange: NASDAQ
#   lot_size: 1
#   fractional: true
#   shortable: true
#   marginable: true
#   trading_hours: "0930-1600"
#   sector: ETF_INDEX

# DISABLED: VOO
# VOO:
#   exchange: NYSE
#   lot_size: 1
#   fractional: true
#   shortable: true
#   marginable: true
#   trading_hours: "0930-1600"
#   sector: ETF_INDEX

# DISABLED: IWM
# IWM:
#   exchange: NYSE
#   lot_size: 1
#   fractional: true
#   shortable: true
#   marginable: true
#   trading_hours: "0930-1600"
#   sector: ETF_INDEX

# DISABLED: XLF
# XLF:
#   exchange: NYSE
#   lot_size: 1
#   fractional: true
#   shortable: true
#   marginable: true
#   trading_hours: "0930-1600"
#   sector: ETF_SECTOR

# DISABLED: XLE
# XLE:
#   exchange: NYSE
#   lot_size: 1
#   fractional: true
#   shortable: true
#   marginable: true
#   trading_hours: "0930-1600"
#   sector: ETF_SECTOR

# DISABLED: SLV
# SLV:
#   exchange: NYSE
#   lot_size: 1
#   fractional: true
#   shortable: true
#   marginable: true
#   trading_hours: "0930-1600"
#   sector: ETF_SECTOR

# DISABLED: EEM
# EEM:
#   exchange: NYSE
#   lot_size: 1
#   fractional: true
#   shortable: true
#   marginable: true
#   trading_hours: "0930-1600"
#   sector: ETF_INDEX

# DISABLED: BAC
# BAC:
#   exchange: NYSE
#   lot_size: 1
#   fractional: true
#   shortable: true
#   marginable: true
#   trading_hours: "0930-1600"
#   sector: FINANCE

# DISABLED: COST
# COST:
#   exchange: NASDAQ
#   lot_size: 1
#   fractional: true
#   shortable: true
#   marginable: true
#   trading_hours: "0930-1600"
#   sector: CONSUMER

# DISABLED: FXE
# FXE:
#   exchange: ARCA
#   lot_size: 1
#   fractional: true
#   shortable: true
#   marginable: true
#   trading_hours: "0930-1600"
#   sector: FX
-----------

-----------
core\__init__.py

-----------

-----------
core\portfolio_builder.py
# CHANGES:
# FIX 1 — sector_counts pre-seeded from existing `positions` before the feasible
#   candidate selection loop begins.  Iterates over every symbol in `positions`,
#   looks up its InstrumentMeta, and increments sector_counts so that already-open
#   TECH (or any other sector) positions are visible to the per-sector cap check.
#   Without this, a bot restart with 3 open TECH positions would admit a 4th because
#   the counter started empty.
#
# FIX 2 — UNKNOWN-sector symbols (meta is None) are now exempt from the sector cap
#   check entirely.  Previously all missing-meta symbols shared one "UNKNOWN" bucket
#   and competed for the same cap slots, incorrectly blocking unrelated symbols.
#   Guard changed to:  if meta is not None and sector_counts.get(...) >= cap: continue
#   Sector counter is only incremented when meta is not None.
#
# All prior changes (Fix C4, Fix H4) are preserved unchanged.

from typing import Dict, List, Any

from adapters.alpaca_adapter import AlpacaAdapter
from core.signals import SignalEngine, Signal
from core.sentiment import SentimentModule
from core.risk_engine import RiskEngine, EquitySnapshot, PositionInfo, ProposedTrade
from config.config import BotConfig
from .portfolio_veto import PortfolioVeto


class PortfolioBuilder:
    """
    Portfolio-level builder:
    - Compute signal_score and side for each instrument.
    - Run pre_trade_checks -> ProposedTrade.
    - Rank by |signal_score| and select until portfolio limits are hit.
    - Optional Sonar veto.
    """

    def __init__(
        self,
        cfg: BotConfig,
        adapter: AlpacaAdapter,
        sentiment: SentimentModule,
        signal_engine: SignalEngine,
        risk_engine: RiskEngine,
    ) -> None:
        self.cfg = cfg
        self.adapter = adapter
        self.sentiment = sentiment
        self.signal_engine = signal_engine
        self.risk_engine = risk_engine
        self.veto = PortfolioVeto()

    def _build_candidate_for_symbol(
        self,
        symbol: str,
        snapshot: EquitySnapshot,
        positions: Dict[str, PositionInfo],
        pending_symbols: set,
    ) -> ProposedTrade:

        # --- DUPLICATE-ORDER & NO EQUITY GUARD ---
        # If we already hold a position in this symbol, skip immediately (no AI API calls).
        if symbol in positions:
            return ProposedTrade(
                symbol=symbol,
                side="buy",
                qty=0.0,
                entry_price=0.0,
                stop_price=0.0,
                take_profit_price=0.0,
                risk_amount=0.0,
                risk_pct_of_equity=0.0,
                sentiment_score=0.0,
                sentiment_scale=0.0,
                signal_score=0.0,
                rationale="Position already open for this symbol",
                rejected_reason="Position already open; skipping to prevent duplicate order and save API calls",
            )

        # If an order is already pending, skip immediately (no AI API calls).
        if symbol in pending_symbols:
            return ProposedTrade(
                symbol=symbol,
                side="buy",
                qty=0.0,
                entry_price=0.0,
                stop_price=0.0,
                take_profit_price=0.0,
                risk_amount=0.0,
                risk_pct_of_equity=0.0,
                sentiment_score=0.0,
                sentiment_scale=0.0,
                signal_score=0.0,
                rationale="Pending order exists for this symbol",
                rejected_reason="Pending order exists; skipping to prevent duplicate order and save API calls",
            )

        # Signal Engine is queried AFTER validation, saving an AI API call if conditions are unmet.
        sig: Signal = self.signal_engine.generate_signal_for_symbol(symbol)

        if sig.side == "skip":
            return ProposedTrade(
                symbol=sig.symbol,
                side="buy",
                qty=0.0,
                entry_price=0.0,
                stop_price=0.0,
                take_profit_price=0.0,
                risk_amount=0.0,
                risk_pct_of_equity=0.0,
                sentiment_score=sig.sentiment_result.score,
                sentiment_scale=0.0,
                signal_score=sig.signal_score,
                rationale=sig.rationale,
                rejected_reason="Signal neutral/skip",
            )

        entry_price = self.adapter.get_last_quote(symbol)

        proposed = self.risk_engine.pre_trade_checks(
            snapshot=snapshot,
            positions=positions,
            symbol=sig.symbol,
            side=sig.side,
            entry_price=entry_price,
            stop_price=sig.stop_price,
            take_profit_price=sig.take_profit_price,
            sentiment=sig.sentiment_result,
            signal_score=sig.signal_score,
            rationale=sig.rationale,
            volatility=sig.volatility,  # Fix H4: was previously omitted
        )
        return proposed

    def build_portfolio(
        self,
        snapshot: EquitySnapshot,
        positions: Dict[str, PositionInfo],
        open_orders: List[Any],
    ) -> List[ProposedTrade]:

        # Defense-in-depth: if fully allocated globally, skip all portfolio generation.
        exposure_cap_notional = snapshot.equity * self.cfg.risk_limits.gross_exposure_cap_pct
        if snapshot.gross_exposure >= exposure_cap_notional or len(positions) >= self.cfg.risk_limits.max_open_positions:
            return []

        pending_symbols = {getattr(o, "symbol", "") for o in open_orders if hasattr(o, "symbol")}

        symbols = list(self.cfg.instruments.keys())
        max_candidates = self.cfg.portfolio.max_candidates_per_loop
        if max_candidates > 0:
            symbols = symbols[:max_candidates]

        candidates: List[ProposedTrade] = []
        for sym in symbols:
            candidate = self._build_candidate_for_symbol(sym, snapshot, positions, pending_symbols)
            candidates.append(candidate)

        feasible: List[ProposedTrade] = [
            t for t in candidates if t.qty > 0 and t.rejected_reason is None
        ]
        if not feasible:
            return []

        feasible.sort(key=lambda t: abs(t.signal_score), reverse=True)

        selected: List[ProposedTrade] = []
        current_gross = snapshot.gross_exposure
        current_open_positions = len(positions)

        # Fix C4: per-sector position counter initialised before the loop.
        sector_counts: Dict[str, int] = {}

        # FIX 1: Pre-seed sector_counts with sectors of already-open positions so
        # that existing holdings count against the per-sector cap from the start.
        # Without this, a bot restart with N open TECH positions would not
        # recognise them and admit further TECH candidates up to the cap.
        for sym in positions:
            meta = self.cfg.instruments.get(sym)
            if meta is not None:
                sector = meta.sector
                sector_counts[sector] = sector_counts.get(sector, 0) + 1
            # FIX 2: If meta is None we do NOT create an "UNKNOWN" entry here —
            # missing-meta symbols are exempt from the cap entirely (see selection
            # loop below), so pre-seeding "UNKNOWN" would be misleading.

        for t in feasible:
            # Secondary guard (defensive): never select a symbol already in positions.
            if t.symbol in positions:
                continue

            notional = t.qty * t.entry_price
            projected_gross = current_gross + abs(notional)

            if projected_gross > snapshot.equity * self.cfg.risk_limits.gross_exposure_cap_pct:
                continue

            new_symbol = t.symbol not in positions
            projected_positions = current_open_positions + (1 if new_symbol else 0)
            if projected_positions > self.cfg.risk_limits.max_open_positions:
                continue

            # Fix C4 / FIX 2: enforce max_positions_per_sector.
            # FIX 2: symbols whose InstrumentMeta is missing (meta is None) are
            # treated as uncapped — they do NOT share an "UNKNOWN" bucket that
            # would incorrectly block unrelated missing-meta symbols.
            meta = self.cfg.instruments.get(t.symbol)
            if meta is not None:
                sector = meta.sector
                if sector_counts.get(sector, 0) >= self.cfg.portfolio.max_positions_per_sector:
                    continue

            selected.append(t)
            current_gross = projected_gross
            if new_symbol:
                current_open_positions = projected_positions
            # Fix C4 / FIX 2: only increment when meta is not None.
            if meta is not None:
                sector_counts[sector] = sector_counts.get(sector, 0) + 1

        if not selected:
            return []

        if self.cfg.portfolio.enable_portfolio_veto:
            selected = self.veto.apply_veto(selected)

        return selected

-----------

-----------
core\portfolio_veto.py
# core/portfolio_veto.py
import json
import os
from typing import Dict, List

import requests

from core.risk_engine import ProposedTrade


class PortfolioVeto:
    """
    Optional portfolio-level veto layer using Perplexity Sonar.

    Given a list of ProposedTrade candidates (already risk-checked),
    prepares a compact prompt and expects a JSON mapping symbol -> 0/1,
    where 0 means veto (do not trade), 1 means allow.

    Controlled by config.portfolio.enable_portfolio_veto.
    """

    def __init__(self) -> None:
        self.apiurl = os.getenv("AI_API_URL", "https://api.perplexity.ai/chat/completions")
        self.apikey = os.getenv("AI_API_KEY")
        if not self.apikey:
            # Fail soft: without API key, veto layer is effectively a no-op
            self.disabled = True
        else:
            self.disabled = False

    def _build_prompt(self, trades: List[ProposedTrade]) -> str:
        lines = []
        for t in trades:
            notional = t.qty * t.entry_price
            line = {
                "symbol": t.symbol,
                "side": t.side,
                "notional": round(notional, 2),
                "signal_score": round(t.signal_score, 3),
                "sentiment_score": round(t.sentiment_score, 3),
                "reason": (t.rationale or "")[:200],
            }
            lines.append(line)

        return (
            "You are a risk-aware portfolio reviewer.\n"
            "You will receive a list of proposed short-term trades for US equities.\n"
            "Each trade includes symbol, side, notional size, a technical signal_score in [-1,1],\n"
            "and a sentiment_score in [-1,1].\n\n"
            "Your task: return a single JSON object mapping each symbol to 0 or 1.\n"
            "1 = trade is acceptable, 0 = veto due to extreme risk, obvious conflict, or\n"
            "major concern (e.g. very unstable situation, illogical rationale).\n"
            "Be conservative but do NOT overfit; use 0 only for clearly problematic trades.\n\n"
            "Input trades:\n"
            + json.dumps(lines, indent=2)
        )

    def apply_veto(self, trades: List[ProposedTrade]) -> List[ProposedTrade]:
        if self.disabled or not trades:
            return trades

        prompt = self._build_prompt(trades)
        headers = {
            "Authorization": f"Bearer {self.apikey}",
            "Content-Type": "application/json",
        }
        payload = {
            "model": "sonar",
            "messages": [
                {
                    "role": "system",
                    "content": (
                        "You are a precise portfolio veto engine. "
                        "You only output strict JSON with {symbol: 0 or 1} entries."
                    ),
                },
                {
                    "role": "user",
                    "content": prompt,
                },
            ],
            "temperature": 0.1,
            "max_tokens": 400,
        }

        try:
            resp = requests.post(self.apiurl, headers=headers, json=payload, timeout=30)
            if not resp.ok:
                print("PortfolioVeto API error", resp.status_code, resp.text)
                return trades

            data = resp.json()
            rawcontent = data["choices"][0]["message"]["content"].strip()
            try:
                result = json.loads(rawcontent)
            except json.JSONDecodeError:
                start = rawcontent.find("{")
                end = rawcontent.rfind("}")
                if start == -1 or end == -1:
                    return trades
                result = json.loads(rawcontent[start : end + 1])

            allowed: List[ProposedTrade] = []
            for t in trades:
                flag = result.get(t.symbol, 1)
                try:
                    flag_int = int(flag)
                except (TypeError, ValueError):
                    flag_int = 1
                if flag_int == 1:
                    allowed.append(t)
            return allowed
        except Exception as e:
            print("PortfolioVeto exception", e)
            return trades

-----------

-----------
core\risk_engine.py
# CHANGES:
# FIX 3 — Kelly path in pre_trade_checks() now applies min_risk_per_trade_pct as
#   the floor for risk_pct, matching the fixed-fractional path.  Changed:
#     max(0.0, raw_risk_pct)
#   to:
#     max(self.limits.min_risk_per_trade_pct, raw_risk_pct)
#   This prevents a very low kelly_f from collapsing risk_pct to zero and
#   producing qty=0 (silently wasted candidate evaluation).
#
# FIX 4 — _vol_history is now a per-symbol Dict[str, deque] instead of a single
#   shared deque.  A single shared deque caused cross-symbol vol contamination:
#   one high-vol symbol (TSLA, NVDA) shifted the median upward and under-sized
#   all normal-vol symbols.
#   In __init__: self._vol_history: Dict[str, deque] = {}
#   In _kelly_fraction(): added symbol: str = "" parameter (default preserves all
#   existing call sites).  Inside the method, per-symbol deque is created on
#   first use (maxlen=200) and all percentile logic uses that deque exclusively.
#   In pre_trade_checks(): _kelly_fraction() call now passes symbol=symbol.
#
# All prior changes (Fix M5, Change 2, Change 4, Improvement A, Improvement C)
# are preserved unchanged.

import math
from collections import deque
from dataclasses import dataclass, field
from typing import Optional, Dict

from .sentiment import SentimentResult
from config.config import RiskLimits, SentimentConfig, InstrumentMeta


@dataclass
class EquitySnapshot:
    equity: float
    cash: float
    portfolio_value: float
    day_trading_buying_power: float
    start_of_day_equity: float
    high_watermark_equity: float
    realized_pl_today: float
    unrealized_pl: float
    gross_exposure: float
    daily_loss_pct: float
    drawdown_pct: float


@dataclass
class PositionInfo:
    symbol: str
    qty: float
    market_price: float
    side: str
    notional: float
    opening_compound: float = 0.0


@dataclass
class ProposedTrade:
    symbol: str
    side: str
    qty: float
    entry_price: float
    stop_price: float
    take_profit_price: float
    risk_amount: float
    risk_pct_of_equity: float
    sentiment_score: float
    sentiment_scale: float
    signal_score: float = 0.0
    rationale: Optional[str] = None
    rejected_reason: Optional[str] = None


class RiskEngine:
    def __init__(
        self,
        risk_limits: RiskLimits,
        sentiment_cfg: SentimentConfig,
        instrument_meta: Dict[str, InstrumentMeta],
    ) -> None:
        self.limits = risk_limits
        self.sentiment_cfg = sentiment_cfg
        self.instrument_meta = instrument_meta
        # FIX 4: per-symbol vol history dict replaces the single shared deque.
        # Key = symbol str, value = deque(maxlen=200).
        # Previously self._vol_history = deque(maxlen=200) was a single pool
        # that mixed all symbols' volatilities, biasing the percentile normaliser.
        self._vol_history: Dict[str, deque] = {}

    def sentiment_scale(self, s: float) -> float:
        """
        Continuous piecewise-linear sentiment scale with no discontinuities.
        [unchanged — see original docstring]
        """
        no_trade_neg = self.sentiment_cfg.no_trade_negative_threshold
        min_sc = self.sentiment_cfg.min_scale
        max_sc = self.sentiment_cfg.max_scale

        if s < no_trade_neg:
            return 0.0
        if s <= 0.0:
            band_width = 0.0 - no_trade_neg
            return min_sc * (s - no_trade_neg) / band_width
        span = max_sc - min_sc
        return min(max_sc, min_sc + span * s)

    def _kelly_fraction(
        self,
        signal_score: float,
        s_scale: float,
        volatility: float,
        s: float = 0.0,
        symbol: str = "",
    ) -> float:
        """
        Compute a Half-Kelly multiplier in [0.0, 1.0].

        FIX 4: added symbol: str = "" parameter.  Volatility history is now
          maintained per-symbol in self._vol_history[symbol] (deque maxlen=200).
          The percentile normaliser therefore reflects each symbol's own vol
          distribution rather than the cross-symbol pool.
          Existing call sites that do not pass symbol still work (default "").

        Improvement A: adaptive vol normalisation.
          volatility is appended to the symbol's deque on every call.
          If len >= 20, vol_norm = percentile(history, kelly_vol_norm_percentile).
          Otherwise vol_norm = 0.002 (warm-up fallback).
          volfactor = volatility / vol_norm if volatility > 0 else 0.0.

        Improvement C: log-odds sentiment blending.
          p_tech = 0.5 + 0.15 * tech_conviction
          log_odds = log(p_tech / (1 - p_tech)) + kelly_sentiment_weight * clamp(s, -1, 1)
          p = clamp(sigmoid(log_odds), 0.35, 0.75)

        Change 4: b uses only tech_conviction.
        s_scale is accepted for backward compatibility but not used here.
        """
        tech_conviction = min(abs(signal_score), 1.0)

        # Improvement C: log-odds blend for p
        p_tech = 0.5 + 0.15 * tech_conviction
        # Guard: p_tech must be strictly in (0, 1) for log to be defined.
        p_tech = max(1e-6, min(1.0 - 1e-6, p_tech))
        log_odds = (
            math.log(p_tech / (1.0 - p_tech))
            + self.limits.kelly_sentiment_weight * max(-1.0, min(1.0, s))
        )
        p = max(0.35, min(0.75, 1.0 / (1.0 + math.exp(-log_odds))))
        q = 1.0 - p
        b = max(1.0, 1.0 + 1.5 * tech_conviction)

        if b <= 0:
            return 0.0

        full_kelly = (p * b - q) / b
        half_kelly = full_kelly * 0.5

        # FIX 4: per-symbol deque — create on first use.
        if symbol not in self._vol_history:
            self._vol_history[symbol] = deque(maxlen=200)
        hist = self._vol_history[symbol]
        hist.append(volatility)

        # Improvement A: adaptive percentile normalisation using symbol-local history.
        if len(hist) >= 20:
            sorted_hist = sorted(hist)
            pct = self.limits.kelly_vol_norm_percentile
            # Linear interpolation for the given percentile.
            idx_f = pct * (len(sorted_hist) - 1)
            idx_lo = int(idx_f)
            idx_hi = min(idx_lo + 1, len(sorted_hist) - 1)
            frac = idx_f - idx_lo
            vol_norm = sorted_hist[idx_lo] + frac * (sorted_hist[idx_hi] - sorted_hist[idx_lo])
            # Guard: never divide by zero even if all history entries are 0.
            if vol_norm <= 0.0:
                vol_norm = 0.002
        else:
            # Warm-up fallback (same as the prior fixed constant).
            vol_norm = 0.002

        volfactor = volatility / vol_norm if volatility > 0 else 0.0
        vol_penalty = 1.0 / (1.0 + volfactor)

        kelly = half_kelly * vol_penalty

        return max(0.0, min(1.0, kelly))

    def pre_trade_checks(
        self,
        snapshot: EquitySnapshot,
        positions: Dict[str, "PositionInfo"],
        symbol: str,
        side: str,
        entry_price: float,
        stop_price: float,
        take_profit_price: float,
        sentiment: SentimentResult,
        signal_score: float = 0.0,
        rationale: Optional[str] = None,
        volatility: float = 0.0,
        sentiment_scale_override: float = -1.0,
    ) -> ProposedTrade:
        """
        Run all pre-trade checks and compute position size.
        [unchanged — see original docstring]
        """
        # 0) Instrument whitelist
        if symbol not in self.instrument_meta:
            return ProposedTrade(
                symbol=symbol, side=side, qty=0.0, entry_price=entry_price,
                stop_price=stop_price, take_profit_price=take_profit_price,
                risk_amount=0.0, risk_pct_of_equity=0.0,
                sentiment_score=sentiment.score, sentiment_scale=0.0,
                signal_score=signal_score, rationale=rationale,
                rejected_reason="Instrument not whitelisted",
            )

        # 1) Hard block for unstable / utterly undesirable sentiment (-2)
        if getattr(sentiment, "raw_discrete", 0) == -2:
            return ProposedTrade(
                symbol=symbol, side=side, qty=0.0, entry_price=entry_price,
                stop_price=stop_price, take_profit_price=take_profit_price,
                risk_amount=0.0, risk_pct_of_equity=0.0,
                sentiment_score=sentiment.score, sentiment_scale=0.0,
                signal_score=signal_score, rationale=rationale,
                rejected_reason="Sentiment -2 (unstable / do not trade)",
            )

        meta = self.instrument_meta[symbol]

        # 2) Sentiment-based sizing scale
        if sentiment_scale_override >= 0.0:
            s_scale = sentiment_scale_override
        else:
            s_scale = self.sentiment_scale(sentiment.score)

        if s_scale == 0.0:
            return ProposedTrade(
                symbol=symbol, side=side, qty=0.0, entry_price=entry_price,
                stop_price=stop_price, take_profit_price=take_profit_price,
                risk_amount=0.0, risk_pct_of_equity=0.0,
                sentiment_score=sentiment.score, sentiment_scale=0.0,
                signal_score=signal_score, rationale=rationale,
                rejected_reason="Sentiment too negative for new trade",
            )

        # 3) Validate stop distance
        stop_distance = abs(entry_price - stop_price)
        if stop_distance <= 0:
            return ProposedTrade(
                symbol=symbol, side=side, qty=0.0, entry_price=entry_price,
                stop_price=stop_price, take_profit_price=take_profit_price,
                risk_amount=0.0, risk_pct_of_equity=0.0,
                sentiment_score=sentiment.score, sentiment_scale=s_scale,
                signal_score=signal_score, rationale=rationale,
                rejected_reason="Invalid stop distance",
            )

        # 4) Risk per trade — fixed-fractional OR Half-Kelly
        if self.limits.enable_kelly_sizing:
            # Change 4 / Improvement C: pass s=sentiment.score to separate tech
            # from sentiment and apply log-odds blending.
            # FIX 4: pass symbol=symbol so _kelly_fraction uses per-symbol vol history.
            kelly_f = self._kelly_fraction(signal_score, s_scale, volatility,
                                           s=sentiment.score, symbol=symbol)
            # Fix M5: apply s_scale as a multiplier so sentiment strength
            # differentiates sizing within the Kelly path.
            kelly_f = kelly_f * s_scale
            raw_risk_pct = kelly_f * self.limits.max_risk_per_trade_pct
            # FIX 3: apply min_risk_per_trade_pct floor (was max(0.0, ...)).
            # Matches the fixed-fractional path and prevents qty=0 from a tiny kelly_f.
            risk_pct = min(
                self.limits.max_risk_per_trade_pct,
                max(self.limits.min_risk_per_trade_pct, raw_risk_pct),
            )
        else:
            raw_risk_pct = self.limits.max_risk_per_trade_pct * s_scale
            risk_pct = min(
                self.limits.max_risk_per_trade_pct,
                max(self.limits.min_risk_per_trade_pct, raw_risk_pct),
            )

        risk_amount = snapshot.equity * risk_pct

        # 5) Size by risk and force whole-lot qty
        qty = risk_amount / stop_distance
        qty = int(qty / meta.lot_size) * meta.lot_size

        if qty <= 0:
            return ProposedTrade(
                symbol=symbol, side=side, qty=0.0, entry_price=entry_price,
                stop_price=stop_price, take_profit_price=take_profit_price,
                risk_amount=0.0, risk_pct_of_equity=0.0,
                sentiment_score=sentiment.score, sentiment_scale=s_scale,
                signal_score=signal_score, rationale=rationale,
                rejected_reason="Calculated quantity is zero",
            )

        # 6) Broker-aware cap
        max_notional_broker = 0.4 * snapshot.equity
        projected_notional = qty * entry_price
        if projected_notional > max_notional_broker:
            max_qty_broker = int(max_notional_broker / entry_price / meta.lot_size) * meta.lot_size
            if max_qty_broker <= 0:
                return ProposedTrade(
                    symbol=symbol, side=side, qty=0.0, entry_price=entry_price,
                    stop_price=stop_price, take_profit_price=take_profit_price,
                    risk_amount=risk_amount, risk_pct_of_equity=risk_pct,
                    sentiment_score=sentiment.score, sentiment_scale=s_scale,
                    signal_score=signal_score, rationale=rationale,
                    rejected_reason="Broker buying power cap per trade",
                )
            qty = max_qty_broker
            projected_notional = qty * entry_price

        # 7) Gross exposure / loss / drawdown / position-count rules
        projected_gross = snapshot.gross_exposure + abs(projected_notional)
        if projected_gross > snapshot.equity * self.limits.gross_exposure_cap_pct:
            return ProposedTrade(
                symbol=symbol, side=side, qty=0.0, entry_price=entry_price,
                stop_price=stop_price, take_profit_price=take_profit_price,
                risk_amount=risk_amount, risk_pct_of_equity=risk_pct,
                sentiment_score=sentiment.score, sentiment_scale=s_scale,
                signal_score=signal_score, rationale=rationale,
                rejected_reason="Gross exposure cap breached",
            )

        if snapshot.daily_loss_pct <= -self.limits.daily_loss_limit_pct:
            return ProposedTrade(
                symbol=symbol, side=side, qty=0.0, entry_price=entry_price,
                stop_price=stop_price, take_profit_price=take_profit_price,
                risk_amount=risk_amount, risk_pct_of_equity=risk_pct,
                sentiment_score=sentiment.score, sentiment_scale=s_scale,
                signal_score=signal_score, rationale=rationale,
                rejected_reason="Daily loss limit breached",
            )

        if snapshot.drawdown_pct <= -self.limits.max_drawdown_pct:
            return ProposedTrade(
                symbol=symbol, side=side, qty=0.0, entry_price=entry_price,
                stop_price=stop_price, take_profit_price=take_profit_price,
                risk_amount=risk_amount, risk_pct_of_equity=risk_pct,
                sentiment_score=sentiment.score, sentiment_scale=s_scale,
                signal_score=signal_score, rationale=rationale,
                rejected_reason="Max drawdown limit breached",
            )

        if len(positions) >= self.limits.max_open_positions and symbol not in positions:
            return ProposedTrade(
                symbol=symbol, side=side, qty=0.0, entry_price=entry_price,
                stop_price=stop_price, take_profit_price=take_profit_price,
                risk_amount=risk_amount, risk_pct_of_equity=risk_pct,
                sentiment_score=sentiment.score, sentiment_scale=s_scale,
                signal_score=signal_score, rationale=rationale,
                rejected_reason="Max open positions exceeded",
            )

        return ProposedTrade(
            symbol=symbol, side=side, qty=qty,
            entry_price=entry_price, stop_price=stop_price,
            take_profit_price=take_profit_price,
            risk_amount=risk_amount, risk_pct_of_equity=risk_pct,
            sentiment_score=sentiment.score, sentiment_scale=s_scale,
            signal_score=signal_score, rationale=rationale,
            rejected_reason=None,
        )

-----------

-----------
core\sentiment.py
# CHANGES:
# Fix C2 — _map_discrete_to_score() now applies confidence_gamma from
#   SentimentConfig.  The formula changes from base * confidence (linear) to
#   base * (confidence ** gamma) where gamma = clamp(self.cfg.confidence_gamma,
#   1.0, 4.0).  The SentimentModule.__init__ now accepts an optional
#   SentimentConfig parameter (cfg) with a default of None; when None a default
#   SentimentConfig() is used.  The special case s_disc == -2 returning hard
#   -1.0 is unchanged.  No variable renames.
# Fix M6 — In _call_ai(), added the same int(round(float(...))) coercion to the
#   raw sentiment value before the membership check, matching the fix applied in
#   ai_client.py scorenews().
# All prior changes (Change 5, Change 6) are preserved unchanged.

from __future__ import annotations

import os
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple

from ai_client import NewsReasoner
from config.config import SentimentConfig


@dataclass
class SentimentResult:
    """
    score: continuous sentiment score in [-1, 1] for risk sizing.
           -1 strongly negative, +1 strongly positive.
           For discrete -2 (utterly undesirable / unstable), score is fixed at -1
           and should trigger no-trade / forced exit logic at the risk engine level.
    raw_discrete: the raw discrete value from the model in {-2, -1, 0, 1}
    rawcompound: legacy field; kept for compatibility, here = score
    ndocuments: number of news items used
    explanation: optional short explanation
    confidence: model-reported confidence in [0, 1]
    """
    score: float
    raw_discrete: int
    rawcompound: float
    ndocuments: int
    explanation: Optional[str] = None
    confidence: float = 0.0


class SentimentModule:
    """
    Sentiment engine backed by Perplexity Sonar via NewsReasoner.

    Implements cost controls:
      (1) TTL-based per-symbol cache to reduce AI calls.
      (2) If no *new* news arrives for a symbol, reuse last-known sentiment (no AI call).
      (6) If last-known raw_discrete == -2, apply a cooldown window during which we do not
          call the AI again for that symbol (even if new news arrives).
    """

    def __init__(self, cfg: Optional[SentimentConfig] = None) -> None:
        self.reasoner = NewsReasoner()
        # Fix C2: store SentimentConfig so _map_discrete_to_score can read
        # confidence_gamma.  Default to a fresh SentimentConfig() if not supplied
        # so all existing call sites (which pass no argument) remain unchanged.
        self.cfg: SentimentConfig = cfg if cfg is not None else SentimentConfig()

        ttl_min = int(os.getenv("SENTIMENT_CACHE_TTL_MIN", "30"))
        ttl_min = max(1, ttl_min)
        self.cache_ttl = timedelta(minutes=ttl_min)

        chaos_cd_min = int(os.getenv("SENTIMENT_CHAOS_COOLDOWN_MIN", "120"))
        chaos_cd_min = max(0, chaos_cd_min)
        self.chaos_cooldown = timedelta(minutes=chaos_cd_min)

        # Cache is the single source of truth for last-known sentiment.
        # symbol -> (SentimentResult, timestamp_utc)
        self._cache: Dict[str, Tuple[SentimentResult, datetime]] = {}

    def _neutral(self, reason: str, ndocs: int = 0) -> SentimentResult:
        return SentimentResult(
            score=0.0,
            raw_discrete=0,
            rawcompound=0.0,
            ndocuments=ndocs,
            explanation=reason,
            confidence=0.0,
        )

    def _map_discrete_to_score(self, s_disc: int, confidence: float) -> float:
        """
        Map discrete sentiment {-2, -1, 0, 1} plus confidence into a continuous score in [-1, 1].

        Fix C2: applies confidence_gamma from SentimentConfig.
          gamma = clamp(self.cfg.confidence_gamma, 1.0, 4.0)
          score = base * (confidence ** gamma)
        gamma=1.0 reproduces the previous linear behaviour.
        gamma=2.0 (default) applies convex weighting: high-confidence scores are
        amplified relative to low-confidence ones.

        Change 6: s_disc == -2 returns -1.0 explicitly and unconditionally.
        Confidence is irrelevant for the chaos case — the score is used as a
        sizing input and -1.0 is already the semantic floor.
        """
        confidence = max(0.0, min(1.0, confidence))

        if s_disc == -2:
            return -1.0          # chaos: always floor, confidence irrelevant

        if s_disc == -1:
            base = -1.0
        elif s_disc == 0:
            base = 0.0
        elif s_disc == 1:
            base = 1.0
        else:
            base = 0.0

        # Fix C2: power-law confidence weighting.
        gamma = max(1.0, min(4.0, float(self.cfg.confidence_gamma)))
        return max(-1.0, min(1.0, base * (confidence ** gamma)))

    def get_cached_sentiment(self, symbol: str) -> Optional[SentimentResult]:
        """
        TTL cache getter.
        Returns a cached sentiment only if it is within the TTL window.
        """
        now = datetime.utcnow()
        cached = self._cache.get(symbol)
        if not cached:
            return None
        result, ts = cached
        if now - ts <= self.cache_ttl:
            return result
        return None

    def _get_last_known(self, symbol: str) -> Optional[Tuple[SentimentResult, datetime]]:
        return self._cache.get(symbol)

    def _set_last_known(self, symbol: str, result: SentimentResult) -> None:
        self._cache[symbol] = (result, datetime.utcnow())

    def _call_ai(self, symbol: str, newsitems: List[dict]) -> SentimentResult:
        """
        Internal: call the AI, parse the result, update the cache, and return a
        SentimentResult. Used by both scorenewsitems() and force_rescore().
        """
        res = self.reasoner.scorenews(symbol, newsitems)

        # Fix M6: coerce raw sentiment to int before membership check.
        try:
            sdisc = int(round(float(res.get("sentiment", 0))))
        except (TypeError, ValueError):
            sdisc = 0
        if sdisc not in (-2, -1, 0, 1):
            sdisc = 0

        try:
            confidence = float(res.get("confidence", 0.0))
        except (TypeError, ValueError):
            confidence = 0.0
        confidence = max(0.0, min(1.0, confidence))

        explanation = res.get("explanation", "") or ""
        score = self._map_discrete_to_score(sdisc, confidence)

        result = SentimentResult(
            score=score,
            raw_discrete=sdisc,
            rawcompound=score,
            ndocuments=len(newsitems),
            explanation=explanation,
            confidence=confidence,
        )
        self._set_last_known(symbol, result)
        return result

    def scorenewsitems(self, symbol: str, newsitems: List[dict]) -> SentimentResult:
        """
        newsitems: list of dicts (typically *new since last check* from Alpaca news API),
                  each with at least 'headline' and/or 'summary'.

        Cost controls:
          - If there are no new news items and we have a last-known sentiment, reuse it. (2)
          - If cached sentiment is still fresh (TTL), reuse it. (1)
          - If last-known sentiment is -2 and still within cooldown, reuse it. (6)
        """
        now = datetime.utcnow()
        last_known = self._get_last_known(symbol)

        # (6) Chaos cooldown: if we recently deemed the symbol "unstable / -2", don't rescore.
        if last_known:
            last_res, last_ts = last_known
            if last_res.raw_discrete == -2 and (now - last_ts) <= self.chaos_cooldown:
                return last_res

        # (2) No new news -> do not call AI; just reuse last-known sentiment if available.
        if not newsitems:
            if last_known:
                return last_known[0]
            return self._neutral("No recent news (no prior sentiment cached).", ndocs=0)

        # (1) TTL cache: if within TTL, reuse cached sentiment even if new news exists.
        # Rationale: avoids frequent rescores when headlines trickle in; TTL bounds staleness.
        cached_fresh = self.get_cached_sentiment(symbol)
        if cached_fresh is not None:
            return cached_fresh

        return self._call_ai(symbol, newsitems)

    def force_rescore(self, symbol: str, newsitems: List[dict]) -> SentimentResult:
        """
        Unconditional AI rescore — bypasses TTL cache and chaos cooldown.

        Use this exclusively for open-position sentiment-exit checks, where stale
        cached data would cause the exit logic to silently produce delta = 0 and
        never fire.

        If newsitems is empty the AI cannot reason about new information; in that
        case we fall back to the last-known cached result (if any) or neutral.
        We do NOT want to exit a position solely because news is thin — the caller
        must decide what to do with a low-confidence neutral result.
        """
        if not newsitems:
            last_known = self._get_last_known(symbol)
            if last_known:
                return last_known[0]
            return self._neutral("No recent news for forced rescore.", ndocs=0)

        return self._call_ai(symbol, newsitems)

    def adaptive_rescore_interval(self, max_abs_s: float) -> int:
        """
        Return a rescore sleep interval in seconds based on the highest
        absolute sentiment score across open positions.
        Thresholds:
            |s| >= 0.8  -> 120s   (high conviction / high risk)
            |s| >= 0.5  -> 300s   (strong signal)
            |s| >= 0.2  -> 600s   (current default)
            |s| <  0.2  -> 900s   (neutral band, minimal alpha)
        """
        if max_abs_s >= 0.8:
            return 120
        if max_abs_s >= 0.5:
            return 300
        if max_abs_s >= 0.2:
            return 600
        return 900

    def adaptive_rescore_interval_hysteresis(self, max_abs_s: float, current_interval: int) -> int:
        target = self.adaptive_rescore_interval(max_abs_s)
        if target == current_interval:
            return current_interval
        boundaries = {120: 0.8, 300: 0.5, 600: 0.2, 900: 0.0}
        current_boundary = boundaries.get(current_interval, 0.0)
        target_boundary  = boundaries.get(target, 0.0)
        midpoint = (current_boundary + target_boundary) / 2.0
        if abs(max_abs_s - midpoint) > 0.05:
            return target
        return current_interval

-----------

-----------
core\signals.py
# CHANGES:
# FIX 5 — generate_signal_for_symbol(): lookback_bars changed from 30 to 45.
#   With period=14, 30 bars gave only 15 smoothing steps (minimum viable).
#   45 bars gives 44 deltas: 14 for the Wilder seed + 30 for smoothing,
#   meeting the conventional 3x-period stability threshold.
#
# FIX 6 — Added _compute_atr() private method that computes the standard
#   Average True Range using bar.h, bar.l, and bars[i-1].c.
#   TR(i) = max(h-l, |h - prev_c|, |l - prev_c|).  ATR = simple mean of
#   last `period` TRs.  Requires period+1 bars; returns 0.0 if insufficient.
#   Returns a price distance (not a ratio).
#   In _decide_side_and_bands(): vol_px now uses atr (with 0.25% fallback)
#   instead of the std-dev-based proxy.  The `volatility` parameter is
#   unchanged in the signature and still used by Kelly sizing via
#   _compute_volatility() -> pre_trade_checks().
#   _decide_side_and_bands() now also accepts `bars` as a parameter so it can
#   call _compute_atr().  generate_signal_for_symbol() passes bars through.
#
# FIX 7 — _compute_simple_momentum_raw(): EMA crossover normalisation now uses
#   ema_crossover_norm_scale (new TechnicalSignalConfig field, default 0.10)
#   instead of momentum_norm_scale (0.05).  Prevents saturation at ±1 for
#   high-momentum equities where EMA divergence exceeds 5%.  getattr fallback
#   ensures backward compatibility if the field is absent on older configs.
#   momentum_norm_scale is still used by _normalize_momentum_trend() unchanged.
#
# All prior changes (Fix M1, Fix M2, Fix M3, Fix L3, Change 3, Improvement B,
# Wilder's RSI) are preserved unchanged.

from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple

import math

from adapters.alpaca_adapter import AlpacaAdapter
from config.config import ENV_MODE, TechnicalSignalConfig
from monitoring.monitor import log_instrument_report

from .sentiment import SentimentModule, SentimentResult


@dataclass
class Signal:
    symbol: str
    side: str  # "buy", "sell", or "skip"
    rationale: str
    sentiment_result: SentimentResult
    stop_price: float
    take_profit_price: float
    signal_score: float
    momentum_score: float
    mean_reversion_score: float
    price_action_score: float
    # Feature 3: expose per-symbol volatility so PortfolioBuilder can forward
    # it to RiskEngine.pre_trade_checks() for Half-Kelly sizing.
    volatility: float = 0.0


class SignalEngine:
    """
    Composite technical signal engine:
      - Momentum/trend
      - Mean reversion (RSI / MA distance proxy)
      - Price action structure

    AI cost controls implemented here:
      (3) Compute technical signal first; if side == "skip", do not fetch news or call AI.
    Suggestion (2) is enforced in SentimentModule.scorenewsitems via reuse when no new news arrives.
    """

    def __init__(
        self,
        adapter: AlpacaAdapter,
        sentiment: SentimentModule,
        technicalcfg: TechnicalSignalConfig,
    ):
        self.adapter = adapter
        self.sentiment = sentiment
        self.technicalcfg = technicalcfg

    def _compute_simple_momentum_raw(self, bars: List) -> float:
        """
        EMA-8 vs EMA-21 crossover signal, normalised to [-1, 1].

        Fix M1: replaced the raw 10-bar return with a fast/slow EMA crossover.
        - Requires at least 22 bars; returns 0.0 if fewer are available.
        - EMA seeded with simple average of first `period` closes.
        - Recursive formula: ema = price * k + ema_prev * (1 - k), k = 2/(period+1).
        - Signal = (ema_fast - ema_slow) / ema_slow, then / ema_crossover_norm_scale, clamped.

        FIX 7: normalisation now uses ema_crossover_norm_scale (default 0.10) via
        getattr fallback, replacing momentum_norm_scale (0.05) which caused ±1
        saturation for high-momentum equities where EMA divergence exceeds 5%.
        Method name and signature are unchanged.
        """
        fast_period = 8
        slow_period = 21
        min_bars = slow_period + 1  # need at least 22 closes

        if not bars or len(bars) < min_bars:
            return 0.0

        closes = [b.c for b in bars]

        k_fast = 2.0 / (fast_period + 1)
        k_slow = 2.0 / (slow_period + 1)

        # Seed fast EMA with SMA of first fast_period bars
        ema_fast = sum(closes[:fast_period]) / fast_period
        for price in closes[fast_period:]:
            ema_fast = price * k_fast + ema_fast * (1.0 - k_fast)

        # Seed slow EMA with SMA of first slow_period bars
        ema_slow = sum(closes[:slow_period]) / slow_period
        for price in closes[slow_period:]:
            ema_slow = price * k_slow + ema_slow * (1.0 - k_slow)

        if ema_slow == 0.0:
            return 0.0

        raw_crossover = (ema_fast - ema_slow) / ema_slow
        # FIX 7: use ema_crossover_norm_scale (wider range) for graded signal.
        # getattr fallback to momentum_norm_scale ensures backward compatibility.
        norm_scale = getattr(self.technicalcfg, "ema_crossover_norm_scale",
                             self.technicalcfg.momentum_norm_scale)
        norm = raw_crossover / norm_scale
        return max(-1.0, min(1.0, norm))

    def _compute_trend_signal_raw(self, bars: List) -> float:
        """
        Simple trend proxy: is price above SMA(20)?
        Returns +1 if > SMA, -1 if < SMA, 0 otherwise.
        """
        if len(bars) < 20:
            return 0.0

        closes = [b.c for b in bars]
        # last 20 bars
        window = closes[-20:]
        sma = sum(window) / len(window)
        current = closes[-1]

        if current > sma:
            return 1.0
        elif current < sma:
            return -1.0
        return 0.0

    def _compute_volatility(self, bars: List) -> float:
        """
        ATR-like proxy or simple std dev of last N closes.
        Uses percentage volatility proxy: Stdev(returns) with Bessel's correction.

        Fix M2: replaced population variance (/ n) with sample variance (/ (n-1)).
        Added guard: if len(returns) < 2, return 0.01 default.
        """
        if len(bars) < 5:
            return 0.01  # fallback

        closes = [b.c for b in bars]
        returns = []
        for i in range(1, len(closes)):
            r = (closes[i] - closes[i-1]) / closes[i-1]
            returns.append(r)

        # Fix M2: guard for insufficient data
        if len(returns) < 2:
            return 0.01

        mean_ret = sum(returns) / len(returns)
        sq_diffs = [(r - mean_ret)**2 for r in returns]
        # Fix M2: Bessel's correction — divide by (n-1) not n
        variance = sum(sq_diffs) / (len(returns) - 1)
        std_dev = math.sqrt(variance)

        # Per-bar std dev as vol proxy
        return std_dev

    def _compute_atr(self, bars: List, period: int = 14) -> float:
        """
        FIX 6: Standard Average True Range computed from bar.h, bar.l, and
        the previous bar's bar.c.

        True Range for bar i:
            TR(i) = max(bar.h - bar.l,
                        abs(bar.h - bars[i-1].c),
                        abs(bar.l - bars[i-1].c))

        ATR = simple average of TR over the last `period` bars.

        Requires at least period+1 bars to compute one TR per bar; returns
        0.0 if insufficient data.

        Returns ATR as a price distance (not a ratio).
        """
        if len(bars) < period + 1:
            return 0.0

        trs = []
        for i in range(1, len(bars)):
            h = bars[i].h
            l = bars[i].l
            prev_c = bars[i - 1].c
            tr = max(h - l, abs(h - prev_c), abs(l - prev_c))
            trs.append(tr)

        # Use the last `period` true ranges for the ATR average.
        recent_trs = trs[-period:]
        if not recent_trs:
            return 0.0
        return sum(recent_trs) / len(recent_trs)

    def _compute_rsi(self, bars: List, period: int = 14) -> float:
        """
        Wilder's EMA-smoothed RSI.

        Algorithm:
          1. Require at least period+1 closes (unchanged guard — returns 50.0
             when insufficient data).
          2. Compute per-bar price changes for ALL available bars.
          3. Seed avg_gain / avg_loss with a plain SMA of the FIRST `period`
             deltas — this is the standard Wilder initialisation.
          4. Roll Wilder's EMA forward over all remaining deltas:
               avg_gain = (avg_gain * (period - 1) + gain) / period
               avg_loss = (avg_loss * (period - 1) + loss) / period
          5. Compute RS and RSI from the final smoothed averages.

        This produces the same values as TradingView / most professional
        charting libraries, unlike the previous simple-average approach which
        used all gains/losses pooled indiscriminately and returned a biased
        result.
        """
        if len(bars) < period + 1:
            return 50.0

        closes = [b.c for b in bars]
        deltas = [closes[i] - closes[i - 1] for i in range(1, len(closes))]

        # Step 3: seed with plain SMA of first `period` deltas
        seed_gains = [max(d, 0.0) for d in deltas[:period]]
        seed_losses = [abs(min(d, 0.0)) for d in deltas[:period]]
        avg_gain = sum(seed_gains) / period
        avg_loss = sum(seed_losses) / period

        # Step 4: Wilder's EMA smoothing over all remaining deltas
        for delta in deltas[period:]:
            gain = max(delta, 0.0)
            loss = abs(min(delta, 0.0))
            avg_gain = (avg_gain * (period - 1) + gain) / period
            avg_loss = (avg_loss * (period - 1) + loss) / period

        # Step 5: RSI
        if avg_loss == 0.0:
            return 100.0

        rs = avg_gain / avg_loss
        return 100.0 - (100.0 / (1.0 + rs))

    def _normalize_momentum_trend(self, mom_raw: float, trend_raw: float) -> float:
        # Scale momentum: if mom is 1%, that's huge in 5min bars.
        # standardizing roughly: mom / 0.005 -> clamped
        mom_score = max(-1.0, min(1.0, mom_raw / self.technicalcfg.momentum_norm_scale))

        # Combine with trend (-1 or 1)
        # 70% momentum value, 30% trend direction
        combined = 0.7 * mom_score + 0.3 * trend_raw
        return combined

    def _normalize_mean_reversion(self, current_price: float, bars: List, rsi: float) -> float:
        """
        Mean reversion score:
        High RSI (>70) -> Negative score (expect pullback)
        Low RSI (<30) -> Positive score (expect bounce)

        Also distance from MA: if price >> MA, revert down (-).
        """
        # RSI component
        rsi_score = 0.0
        if rsi > self.technicalcfg.rsi_overbought:
            # e.g. 75 -> -0.5
            rsi_score = -1.0 * (rsi - 70) / 30.0
        elif rsi < self.technicalcfg.rsi_oversold:
            # e.g. 25 -> +0.5
            rsi_score = 1.0 * (30 - rsi) / 30.0

        # MA distance component
        if len(bars) < 20:
            ma_score = 0.0
        else:
            closes = [b.c for b in bars[-20:]]
            sma = sum(closes) / len(closes)
            # (price - sma) / sma
            dist = (current_price - sma) / sma
            # if dist is +1%, score is negative (revert)
            # scale: 0.05 (5%) -> full -1.0
            ma_score = -1.0 * (dist / self.technicalcfg.ma_distance_norm_scale)

        return max(-1.0, min(1.0, 0.5 * rsi_score + 0.5 * ma_score))

    def _compute_price_action_score(self, bars: List, current_price: float) -> float:
        """
        Simple breakout detection:
        If current price > highest of last N bars -> +1 (Breakout)
        If current price < lowest of last N bars -> -1 (Breakdown)

        Fix M3: returns 0.0 immediately when the market is closed to prevent
        the permanent -1.0 artifact that appears outside regular trading hours
        (when the current bar's price equals the most recent close and sits
        below the historical high of the lookback window).
        """
        # Fix M3: suppress price action score when market is closed.
        if not self.adapter.get_market_open():
            return 0.0

        if len(bars) < self.technicalcfg.breakout_lookback_bars:
            return 0.0

        window = bars[-self.technicalcfg.breakout_lookback_bars:-1]  # exclude current
        highs = [b.h for b in window]
        lows = [b.l for b in window]

        recent_high = max(highs)
        recent_low = min(lows)

        if current_price > recent_high:
            return 1.0
        elif current_price < recent_low:
            return -1.0

        return 0.0

    def _combine_technical_scores(
        self, mom: float, mr: float, pa: float
    ) -> Tuple[float, bool]:
        """
        Compute the weighted composite signal score and flag whether the
        momentum/mean-reversion conflict dampener was applied.

        Weights from config (unchanged):
            weight_momentum_trend  * mom
            weight_mean_reversion  * mr
            weight_price_action    * pa

        Conflict dampener:
            When momentum_score (mom) and mean_reversion_score (mr) have
            OPPOSITE signs their product is negative, indicating the move is
            already extended (momentum maxed) while mean-reversion pushes back.
            In that case the raw weighted sum is multiplied by
            `conflict_dampener_penalty` (default 0.6), reducing apparent
            conviction by 40%.

            Same-sign or zero sub-signals (product >= 0) are NOT penalised —
            existing behaviour for clean / aligned setups is fully preserved.

        Returns:
            (signal_score: float, dampened: bool)
        """
        raw = (
            self.technicalcfg.weight_momentum_trend * mom
            + self.technicalcfg.weight_mean_reversion * mr
            + self.technicalcfg.weight_price_action * pa
        )

        # Apply dampener only when momentum and mean-reversion actively conflict.
        dampened = False
        if mom * mr < 0:
            # Fix L3: direct attribute access — field is now explicit in TechnicalSignalConfig.
            penalty = float(self.technicalcfg.conflict_dampener_penalty)
            raw = raw * penalty
            dampened = True

        return max(-1.0, min(1.0, raw)), dampened

    def _decide_side_and_bands(
        self,
        last_price: float,
        volatility: float,
        signal_score: float,
        symbol: str = "",
        bars: List = None,
    ) -> Tuple[str, float, float]:
        """
        Determine the trade side and compute stop/take-profit price bands.

        FIX 6: vol_px is now derived from ATR (_compute_atr()) instead of the
        std-dev-based proxy.  ATR uses bar.h, bar.l, and bars[i-1].c for a
        proper measure of true daily range.  If ATR is zero or bars are
        unavailable, falls back to 0.25% of last_price.
        The `volatility` parameter (std-dev) remains in the signature and is
        still used downstream by _compute_volatility() -> pre_trade_checks() ->
        _kelly_fraction() for Kelly sizing.

        Improvement B: When TechnicalSignalConfig.enable_dynamic_threshold is
        True, thresholds are adjusted asymmetrically using sentiment_th_scale:
          s_adj = clamp(cached_s, -0.5, 0.5)
          long_th_adj  = long_th  * (1.0 - sentiment_th_scale * s_adj / 0.5)
          short_th_adj = short_th * (1.0 + sentiment_th_scale * s_adj / 0.5)

        Sign logic (CONFIRMED CORRECT):
          short_th is negative.
          Positive s_adj (bullish sentiment):
            long_th_adj  < long_th   -> easier to go long  (threshold shrinks)
            short_th_adj > short_th  -> harder to go short (negative * (1+x) is
                                        more negative, i.e. a stricter bar)
          Negative s_adj (bearish sentiment):
            long_th_adj  > long_th   -> harder to go long
            short_th_adj < short_th  -> easier to go short

        The config object is NEVER mutated — adjustments are local variables only.
        When enable_dynamic_threshold is False (the default), long_th_adj ==
        long_th and short_th_adj == short_th, preserving existing behaviour.
        """
        long_th = float(self.technicalcfg.long_threshold)
        short_th = float(self.technicalcfg.short_threshold)

        # Improvement B: asymmetric sentiment-adjusted thresholds (local only).
        # When enable_dynamic_threshold is False (default), adj == raw threshold.
        if getattr(self.technicalcfg, "enable_dynamic_threshold", False) and symbol:
            cached_s_result = self.sentiment.get_cached_sentiment(symbol)
            cached_s = cached_s_result.score if cached_s_result is not None else 0.0
            sentiment_th_scale = float(
                getattr(self.technicalcfg, "sentiment_th_scale", 0.25)
            )
            s_adj = max(-0.5, min(0.5, cached_s))
            # Asymmetric adjustment:
            # long_th_adj  shrinks when sentiment positive (easier to go long).
            # short_th_adj becomes more negative when sentiment positive
            # (harder to go short) because short_th is negative and
            # (1.0 + positive_value) > 1.0, making the product more negative.
            long_th_adj  = long_th  * (1.0 - sentiment_th_scale * s_adj / 0.5)
            short_th_adj = short_th * (1.0 + sentiment_th_scale * s_adj / 0.5)
        else:
            long_th_adj  = long_th
            short_th_adj = short_th

        side = "skip"
        if signal_score >= long_th_adj:
            side = "buy"
        elif signal_score <= short_th_adj:
            side = "sell"

        # FIX 6: use ATR-based vol_px for stop/TP band calculation.
        # ATR gives a proper true-range measure; std-dev proxy underestimates.
        if bars:
            atr = self._compute_atr(bars)
        else:
            atr = 0.0
        if atr <= 0.0:
            atr = 0.0025 * last_price   # fallback: 0.25% of price
        vol_px = atr

        stop_mult = float(self.technicalcfg.base_stop_vol_mult)
        tp_mult = float(self.technicalcfg.base_tp_vol_mult)

        # Scale TP slightly with conviction but clamp.
        min_tp_scale = float(self.technicalcfg.min_tp_scale_from_signal)
        max_tp_scale = float(self.technicalcfg.max_tp_scale_from_signal)
        tp_scale = max(min_tp_scale, min(max_tp_scale, 1.0 + 0.3 * abs(signal_score)))

        if side == "buy":
            stop = last_price - stop_mult * vol_px
            tp = last_price + tp_mult * vol_px * tp_scale
        elif side == "sell":
            stop = last_price + stop_mult * vol_px
            tp = last_price - tp_mult * vol_px * tp_scale
        else:
            # Still return bands, but they won't be used.
            stop = last_price
            tp = last_price

        return side, float(stop), float(tp)

    def _get_news_items(self, symbol: str) -> List[Dict]:
        """
        Fetch news from Alpaca adapter.
        Here we just ask for latest 10 items.
        """
        return self.adapter.get_news(symbol, limit=10)

    def generate_signal_for_symbol(self, symbol: str) -> Signal:
        last_trade = self.adapter.get_last_quote(symbol)
        # FIX 5: increased from 30 to 45 bars (3x period=14) for stable Wilder RSI.
        bars = self.adapter.get_recent_bars(symbol, timeframe="5Min", lookback_bars=45)

        momentum_raw = self._compute_simple_momentum_raw(bars)
        trend_raw = self._compute_trend_signal_raw(bars)
        volatility = self._compute_volatility(bars)
        rsi = self._compute_rsi(bars)

        momentum_score = self._normalize_momentum_trend(momentum_raw, trend_raw)
        mean_reversion_score = self._normalize_mean_reversion(last_trade, bars, rsi)
        price_action_score = self._compute_price_action_score(bars, last_trade)

        signal_score, dampened = self._combine_technical_scores(
            momentum_score, mean_reversion_score, price_action_score
        )

        # Change 3: thread symbol and bars through so _decide_side_and_bands can
        # look up the cached sentiment for dynamic threshold adjustment (Improvement B)
        # and compute ATR from bar.h / bar.l / bar.c (FIX 6).
        side, stop_price, take_profit_price = self._decide_side_and_bands(
            last_price=last_trade,
            volatility=volatility,
            signal_score=signal_score,
            symbol=symbol,
            bars=bars,
        )

        dampener_tag = " [CONFLICT DAMPENED]" if dampened else ""

        # AI cost control (3): skip sentiment entirely when the technical signal
        # is neutral — saves an API call.
        if side == "skip":
            neutral_sentiment = SentimentResult(
                score=0.0,
                raw_discrete=0,
                rawcompound=0.0,
                ndocuments=0,
                explanation="Technical signal neutral; sentiment not evaluated.",
                confidence=0.0,
            )
            return Signal(
                symbol=symbol,
                side="skip",
                rationale=f"Technical signal neutral{dampener_tag}",
                sentiment_result=neutral_sentiment,
                stop_price=stop_price,
                take_profit_price=take_profit_price,
                signal_score=signal_score,
                momentum_score=momentum_score,
                mean_reversion_score=mean_reversion_score,
                price_action_score=price_action_score,
                volatility=volatility,
            )

        news_items = self._get_news_items(symbol)
        sentiment_result = self.sentiment.scorenewsitems(symbol, news_items)

        # Sentiment no-trade block
        if sentiment_result.score < self.sentiment.cfg.no_trade_negative_threshold:
            return Signal(
                symbol=symbol,
                side="skip",
                rationale=(
                    f"Sentiment too negative: {sentiment_result.score:.3f} "
                    f"< threshold {self.sentiment.cfg.no_trade_negative_threshold}"
                    f"{dampener_tag}"
                ),
                sentiment_result=sentiment_result,
                stop_price=stop_price,
                take_profit_price=take_profit_price,
                signal_score=signal_score,
                momentum_score=momentum_score,
                mean_reversion_score=mean_reversion_score,
                price_action_score=price_action_score,
                volatility=volatility,
            )

        rationale = (
            f"side={side} signal={signal_score:.3f} "
            f"mom={momentum_score:.3f} mr={mean_reversion_score:.3f} "
            f"pa={price_action_score:.3f} "
            f"sentiment={sentiment_result.score:.3f}{dampener_tag}"
        )

        log_instrument_report(
            symbol=symbol,
            signal_score=signal_score,
            sentiment=sentiment_result,
            momentum_score=momentum_score,
            mean_reversion_score=mean_reversion_score,
            price_action_score=price_action_score,
            env_mode=ENV_MODE,
        )

        return Signal(
            symbol=symbol,
            side=side,
            rationale=rationale,
            sentiment_result=sentiment_result,
            stop_price=stop_price,
            take_profit_price=take_profit_price,
            signal_score=signal_score,
            momentum_score=momentum_score,
            mean_reversion_score=mean_reversion_score,
            price_action_score=price_action_score,
            volatility=volatility,
        )

-----------

-----------
execution\__init__.py

-----------

-----------
execution\order_executor.py
# CHANGES:
# - No functional changes in this file relative to the prior version.
#   This is a full reconstruction of the file after a truncated output.
#   All logic, variable names, docstrings, and method signatures are
#   preserved exactly as they were in the previous revision.

import logging
import time
from typing import Dict, Optional

from alpaca_trade_api.rest import APIError

from adapters.alpaca_adapter import AlpacaAdapter
from config.config import BotConfig, ExecutionConfig, SentimentConfig
from core.risk_engine import PositionInfo, ProposedTrade
from core.sentiment import SentimentModule, SentimentResult
from monitoring.monitor import (
    log_proposed_trade,
    log_sentiment_close_decision,
    log_sentiment_position_check,
)

logger = logging.getLogger("tradebot")


# ── Module-level sentinel used by main.py ────────────────────────────────────


def _check_and_exit_on_sentiment(
    positions: Dict[str, PositionInfo],
    adapter: AlpacaAdapter,
    sentiment_module: SentimentModule,
    executor: "OrderExecutor",
    cfg: BotConfig,
) -> None:
    """
    For every open position, force-rescore sentiment and compare the current
    compound score against the score recorded at entry time
    (PositionInfo.opening_compound).

    Three exit tiers (from SentimentConfig):

    1. Hard exit (chaos):
       raw_discrete == -2  →  close unconditionally, no delta check.

    2. Strong exit:
       delta > strong_exit_delta_threshold  AND
       confidence > strong_exit_confidence_min
       Fires on large sentiment deterioration even at moderate confidence.

    3. Soft exit:
       delta > soft_exit_delta_threshold  AND
       confidence > exit_confidence_min
       Catches partial deterioration (e.g. +0.7 → 0.0, delta=0.70).

    delta is defined as:
        delta = opening_compound - current_sentiment.score
    A positive delta means sentiment has worsened since entry.

    The effective delta_threshold used for the monitor log is the *lowest*
    threshold that could have fired (soft wins if confidence qualifies, else
    strong).  This keeps the log display consistent with the actual decision.
    """
    sent_cfg: SentimentConfig = cfg.sentiment
    env_mode: str = cfg.env_mode

    for symbol, pos in positions.items():
        news_items = adapter.get_news(symbol, limit=10)
        current_sentiment: SentimentResult = sentiment_module.force_rescore(
            symbol, news_items
        )

        opening_compound: float = pos.opening_compound
        current_score: float = current_sentiment.score
        delta: float = opening_compound - current_score

        # ── Determine which (if any) exit tier fires ──────────────────────────
        hard_exit = current_sentiment.raw_discrete == -2

        strong_exit = (
            not hard_exit
            and delta > sent_cfg.strong_exit_delta_threshold
            and current_sentiment.confidence > sent_cfg.strong_exit_confidence_min
        )

        soft_exit = (
            not hard_exit
            and not strong_exit
            and delta > sent_cfg.soft_exit_delta_threshold
            and current_sentiment.confidence > sent_cfg.exit_confidence_min
        )

        closing = hard_exit or strong_exit or soft_exit

        # Effective threshold for monitor display.
        if hard_exit:
            display_threshold = 0.0          # chaos: delta is irrelevant
            close_reason = "hard_exit_chaos_discrete_minus2"
        elif strong_exit:
            display_threshold = sent_cfg.strong_exit_delta_threshold
            close_reason = "strong_exit_large_delta"
        elif soft_exit:
            display_threshold = sent_cfg.soft_exit_delta_threshold
            close_reason = "soft_exit_partial_deterioration"
        else:
            # Use soft threshold as reference for the "HOLDING" display.
            display_threshold = sent_cfg.soft_exit_delta_threshold
            close_reason = "no_exit"

        log_sentiment_position_check(
            position=pos,
            entry_compound=opening_compound,
            current_sentiment=current_sentiment,
            delta=delta,
            delta_threshold=display_threshold,
            confidence_min=(
                sent_cfg.exit_confidence_min
                if not hard_exit
                else 0.0
            ),
            closing=closing,
            close_reason=close_reason,
            env_mode=env_mode,
            stop_price=None,
            take_profit_price=None,
        )

        if closing:
            executor.close_position_due_to_sentiment(
                position=pos,
                sentiment=current_sentiment,
                reason=close_reason,
                env_mode=env_mode,
            )


# ── OrderExecutor ─────────────────────────────────────────────────────────────


class OrderExecutor:
    """
    Submits entry and exit orders to Alpaca.

    Execution path (execute_proposed_trade):
      1. Log the proposed trade.
      2. If live_trading_enabled is False (paper mode guard), skip submission.
      3. Cancel any open orders for the symbol before entering.
      4. Submit a bracket order (entry + OCO TP/stop) when both
         enable_take_profit and enable_trailing_stop are True.
      5. Fall back to entry + standalone trailing-stop when only
         enable_trailing_stop is True.
      6. Fall back to plain market order when neither exit type is configured.

    Sentiment exit path (close_position_due_to_sentiment):
      Submits a market order to flatten the position on the opposing side,
      cancelling open orders for the symbol first to avoid qty conflicts.
    """

    def __init__(
        self,
        adapter: AlpacaAdapter,
        env_mode: str,
        live_trading_enabled: bool,
        execution_cfg: ExecutionConfig,
    ) -> None:
        self.adapter = adapter
        self.env_mode = env_mode
        self.live_trading_enabled = live_trading_enabled
        self.execution_cfg = execution_cfg

    # ── Internal helpers ──────────────────────────────────────────────────────

    def _cancel_all_open_orders_for_symbol(self, symbol: str) -> None:
        """Cancel every open order for *symbol*.  Errors are logged and swallowed."""
        try:
            open_orders = self.adapter.list_orders(status="open")
            for order in open_orders:
                if getattr(order, "symbol", None) == symbol:
                    try:
                        self.adapter.cancel_order(order.id)
                        logger.info(
                            f"Cancelled open order {order.id} for {symbol} "
                            f"before new submission."
                        )
                    except Exception as e:
                        logger.warning(
                            f"Could not cancel order {order.id} for {symbol}: {e}"
                        )
        except Exception as e:
            logger.warning(f"_cancel_all_open_orders_for_symbol({symbol}) error: {e}")

    def _exit_side(self, position_side: str) -> str:
        """Return the closing side for a given position side."""
        return "sell" if position_side == "long" else "buy"

    # ── Entry execution ───────────────────────────────────────────────────────

    def execute_proposed_trade(self, proposed: ProposedTrade) -> Optional[object]:
        """
        Execute a ProposedTrade.

        Returns the Alpaca order object on success, or None if skipped/failed.
        """
        log_proposed_trade(proposed, self.env_mode)

        if proposed.rejected_reason is not None or proposed.qty <= 0:
            return None

        if not self.live_trading_enabled:
            logger.info(
                f"[PAPER] Skipping live order submission for {proposed.symbol} "
                f"(live_trading_enabled=False)."
            )
            return None

        symbol = proposed.symbol
        qty = proposed.qty
        side = proposed.side
        stop_price = proposed.stop_price
        take_profit_price = proposed.take_profit_price

        self._cancel_all_open_orders_for_symbol(symbol)

        use_tp = self.execution_cfg.enable_take_profit
        use_ts = self.execution_cfg.enable_trailing_stop

        try:
            if use_tp and use_ts:
                # Bracket order: entry market + OCO (TP limit + stop-loss).
                order = self.adapter.submit_bracket_order(
                    symbol=symbol,
                    qty=qty,
                    side=side,
                    stop_price=stop_price,
                    take_profit_price=take_profit_price,
                    time_in_force=self.execution_cfg.entry_time_in_force,
                )
                logger.info(
                    f"Bracket order submitted for {symbol}: side={side} qty={qty} "
                    f"stop={stop_price:.2f} tp={take_profit_price:.2f} "
                    f"order_id={getattr(order, 'id', 'N/A')}"
                )
            elif use_ts:
                # Entry market order + separate trailing-stop exit.
                order = self.adapter.submit_market_order(
                    symbol=symbol,
                    qty=qty,
                    side=side,
                    time_in_force=self.execution_cfg.entry_time_in_force,
                )
                logger.info(
                    f"Market order submitted for {symbol}: side={side} qty={qty} "
                    f"order_id={getattr(order, 'id', 'N/A')}"
                )
                # Wait briefly for fill before attaching stop.
                time.sleep(self.execution_cfg.post_entry_fill_timeout_sec)

                exit_side = self._exit_side(side)
                try:
                    stop_order = self.adapter.submit_trailing_stop_order(
                        symbol=symbol,
                        qty=qty,
                        side=exit_side,
                        trail_percent=self.execution_cfg.trailing_stop_percent,
                        time_in_force=self.execution_cfg.exit_time_in_force,
                    )
                    logger.info(
                        f"Trailing stop attached for {symbol}: side={exit_side} qty={qty} "
                        f"trail%={self.execution_cfg.trailing_stop_percent} "
                        f"order_id={getattr(stop_order, 'id', 'N/A')}"
                    )
                except APIError as e:
                    logger.warning(
                        f"Trailing stop placement failed for {symbol}: {e}"
                    )
            else:
                # Plain market order, no automated exit leg.
                order = self.adapter.submit_market_order(
                    symbol=symbol,
                    qty=qty,
                    side=side,
                    time_in_force=self.execution_cfg.entry_time_in_force,
                )
                logger.info(
                    f"Market order (no exit leg) submitted for {symbol}: "
                    f"side={side} qty={qty} "
                    f"order_id={getattr(order, 'id', 'N/A')}"
                )

            return order

        except APIError as e:
            logger.error(f"execute_proposed_trade APIError for {symbol}: {e}")
            return None
        except Exception as e:
            logger.error(f"execute_proposed_trade unexpected error for {symbol}: {e}")
            return None

    # ── Sentiment-driven position close ───────────────────────────────────────

    def close_position_due_to_sentiment(
        self,
        position: PositionInfo,
        sentiment: SentimentResult,
        reason: str,
        env_mode: str,
    ) -> None:
        """
        Flatten *position* with a market order on the opposing side.

        Steps:
          1. Cancel all open orders for the symbol (avoids qty-reservation
             conflicts with any bracket/trailing-stop legs still live).
          2. Submit a market order for the full position qty on the exit side.
          3. Log the closure via log_sentiment_close_decision.

        Errors are caught and logged; the method never raises so the main loop
        can continue processing other positions.
        """
        symbol = position.symbol
        qty = abs(position.qty)
        exit_side = self._exit_side(position.side)

        log_sentiment_close_decision(
            symbol=symbol,
            side=exit_side,
            qty=qty,
            sentiment_score=sentiment.score,
            confidence=sentiment.confidence,
            explanation=sentiment.explanation or "",
            env_mode=env_mode,
            reason=reason,
        )

        if not self.live_trading_enabled:
            logger.info(
                f"[PAPER] Skipping live sentiment-close for {symbol} "
                f"(live_trading_enabled=False)."
            )
            return

        self._cancel_all_open_orders_for_symbol(symbol)

        try:
            order = self.adapter.submit_market_order(
                symbol=symbol,
                qty=qty,
                side=exit_side,
                time_in_force=self.execution_cfg.exit_time_in_force,
            )
            logger.info(
                f"Sentiment-close market order submitted for {symbol}: "
                f"side={exit_side} qty={qty} reason={reason} "
                f"order_id={getattr(order, 'id', 'N/A')}"
            )
        except APIError as e:
            logger.error(
                f"close_position_due_to_sentiment APIError for {symbol}: {e}"
            )
        except Exception as e:
            logger.error(
                f"close_position_due_to_sentiment unexpected error for {symbol}: {e}"
            )

-----------

-----------
execution\position_manager.py
# CHANGES:
# - No functional changes from baseline.
# - get_positions() accepts an optional opening_compounds dict and patches
#   each PositionInfo.opening_compound from it so the sentiment-exit delta
#   check in main._check_and_exit_on_sentiment() has a valid entry baseline.

import logging
from typing import Dict, Optional

from adapters.alpaca_adapter import AlpacaAdapter
from core.risk_engine import PositionInfo

logger = logging.getLogger("tradebot")


class PositionManager:
    """
    Maps raw Alpaca REST positions into typed PositionInfo objects.

    Responsibilities:
      - Fetch all open positions from the broker.
      - Convert raw Alpaca position objects into PositionInfo dataclasses.
      - Patch opening_compound from the in-memory registry (_opening_compounds)
        so downstream sentiment-exit logic has a valid entry-time baseline.
    """

    def __init__(self, adapter: AlpacaAdapter) -> None:
        self.adapter = adapter

    def get_positions(
        self,
        opening_compounds: Optional[Dict[str, float]] = None,
    ) -> Dict[str, PositionInfo]:
        """
        Fetch and map all open Alpaca positions.

        Parameters
        ----------
        opening_compounds : dict, optional
            Registry of {symbol: entry_sentiment_score} maintained by main.
            When provided, each PositionInfo.opening_compound is populated
            so that _check_and_exit_on_sentiment() can compute a meaningful delta.

        Returns
        -------
        Dict[str, PositionInfo]
            Keyed by symbol string.
        """
        raw_positions = self.adapter.list_positions()
        positions: Dict[str, PositionInfo] = {}

        for pos in raw_positions:
            try:
                symbol: str = str(pos.symbol)
                qty: float = float(pos.qty)
                market_price: float = float(pos.current_price)
                side: str = str(pos.side)  # "long" or "short"
                notional: float = abs(qty * market_price)

                opening_compound: float = 0.0
                if opening_compounds is not None:
                    opening_compound = float(opening_compounds.get(symbol, 0.0))

                positions[symbol] = PositionInfo(
                    symbol=symbol,
                    qty=qty,
                    market_price=market_price,
                    side=side,
                    notional=notional,
                    opening_compound=opening_compound,
                )
            except Exception as e:
                logger.warning(f"PositionManager: failed to parse position {getattr(pos, 'symbol', '?')}: {e}")

        return positions

-----------

-----------
main.py
# CHANGES:
# - Added _load_opening_compounds() / _persist_opening_compounds() helpers that
#   read/write the opening_compounds sub-key of equity_state.json so entry-time
#   sentiment baselines survive bot restarts.
# - Added load_equity_state() / save_equity_state() for equity watermark
#   persistence.
# - get_equity_snapshot_from_account() uses the persisted state for
#   start_of_day_equity and high_watermark_equity.
# - _check_and_exit_on_sentiment() implements directional delta exit logic
#   (Change 1b): only adverse sentiment shifts fire exits.
# - main() loop integrates: kill switch → sentiment exit → portfolio build →
#   adaptive sleep with hysteresis (Change 5 / Improvement D).

import json
import logging
import time
from datetime import date
from pathlib import Path
from typing import Dict, List, Optional

from adapters.alpaca_adapter import AlpacaAdapter
from config.config import load_config
from core.portfolio_builder import PortfolioBuilder
from core.risk_engine import RiskEngine, EquitySnapshot, PositionInfo
from core.sentiment import SentimentModule, SentimentResult
from core.signals import SignalEngine
from execution.order_executor import OrderExecutor
from execution.position_manager import PositionManager
from monitoring.kill_switch import KillSwitch
from monitoring.monitor import (
    log_equity_snapshot,
    log_environment_switch,
    log_kill_switch_state,
    log_portfolio_overview,
    log_sentiment_position_check,
    setup_logging,
)

logger = logging.getLogger("tradebot")

_EQUITY_STATE_PATH = Path("equity_state.json")


# ── Equity state persistence ───────────────────────────────────────────────────

def load_equity_state() -> dict:
    if _EQUITY_STATE_PATH.exists():
        try:
            with _EQUITY_STATE_PATH.open("r") as f:
                return json.load(f)
        except Exception as e:
            logger.warning(f"load_equity_state: could not read state file: {e}")
    return {}


def save_equity_state(state: dict) -> None:
    try:
        with _EQUITY_STATE_PATH.open("w") as f:
            json.dump(state, f, indent=2)
    except Exception as e:
        logger.warning(f"save_equity_state: could not write state file: {e}")


# ── Opening compound persistence ───────────────────────────────────────────────

def _load_opening_compounds() -> Dict[str, float]:
    """Load the opening_compounds registry from equity_state.json."""
    state = load_equity_state()
    raw = state.get("opening_compounds", {})
    result: Dict[str, float] = {}
    for sym, val in raw.items():
        try:
            result[str(sym)] = float(val)
        except (TypeError, ValueError):
            pass
    return result


def _persist_opening_compounds(opening_compounds: Dict[str, float]) -> None:
    """
    Write the opening_compounds sub-key to equity_state.json.
    Does NOT overwrite unrelated keys (start_of_day_equity, etc.).
    """
    state = load_equity_state()
    state["opening_compounds"] = {sym: float(v) for sym, v in opening_compounds.items()}
    save_equity_state(state)


# ── Equity snapshot ────────────────────────────────────────────────────────────

def get_equity_snapshot_from_account(
    acct,
    positions: Dict[str, PositionInfo],
) -> EquitySnapshot:
    equity = float(acct.equity)
    cash = float(acct.cash)
    portfolio_value = float(acct.portfolio_value)

    state = load_equity_state()
    today_str = date.today().isoformat()
    last_day = state.get("last_trading_day")
    start_of_day_equity = float(state.get("start_of_day_equity", equity))
    high_watermark_equity = float(state.get("high_watermark_equity", equity))

    if last_day != today_str:
        start_of_day_equity = equity
        high_watermark_equity = equity
        state["last_trading_day"] = today_str

    if equity > high_watermark_equity:
        high_watermark_equity = equity

    if start_of_day_equity > 0:
        daily_loss_pct = (equity - start_of_day_equity) / start_of_day_equity
    else:
        daily_loss_pct = 0.0

    if high_watermark_equity > 0:
        drawdown_pct = (equity - high_watermark_equity) / high_watermark_equity
    else:
        drawdown_pct = 0.0

    state["start_of_day_equity"] = start_of_day_equity
    state["high_watermark_equity"] = high_watermark_equity
    # NOTE: do not write opening_compounds here — that key is managed exclusively
    # by main to avoid accidental overwrites during snapshot refreshes.
    save_equity_state(state)

    realized_pl_today = float(getattr(acct, "day_trade_pl", 0.0))
    unrealized_pl = float(getattr(acct, "unrealized_pl", 0.0))
    gross_exposure = sum(abs(p.notional) for p in positions.values())

    return EquitySnapshot(
        equity=equity,
        cash=cash,
        portfolio_value=portfolio_value,
        day_trading_buying_power=float(
            getattr(
                acct,
                "day_trading_buying_power",
                getattr(acct, "daytrading_buying_power", getattr(acct, "buying_power", 0.0)),
            )
        ),
        start_of_day_equity=start_of_day_equity,
        high_watermark_equity=high_watermark_equity,
        realized_pl_today=realized_pl_today,
        unrealized_pl=unrealized_pl,
        gross_exposure=gross_exposure,
        daily_loss_pct=daily_loss_pct,
        drawdown_pct=drawdown_pct,
    )


# ── Sentiment-exit check ───────────────────────────────────────────────────────

def _check_and_exit_on_sentiment(
    positions: Dict[str, PositionInfo],
    adapter: AlpacaAdapter,
    sentiment_module: SentimentModule,
    executor: OrderExecutor,
    cfg,
) -> None:
    """
    Iterate over ALL open positions.  For each one:
      1. Fetch fresh news; force_rescore() bypasses TTL cache and chaos cooldown.
      2. Hard exit unconditionally if raw_discrete == -2 (chaos event).
      3. Strong exit if delta > strong_exit_delta_threshold AND
         confidence > strong_exit_confidence_min.
      4. Soft exit if delta > soft_exit_delta_threshold AND
         confidence > exit_confidence_min.
      5. Emit a formatted per-instrument block via log_sentiment_position_check().

    opening_compound is sourced directly from PositionInfo.opening_compound,
    which main patches in from _opening_compounds after each entry fill.
    This survives TTL expiry and bot restarts because opening_compounds is
    persisted to equity_state.json.

    Change 1b: delta is now directional so only adverse sentiment shifts fire:
      LONG  position: delta = entry_sentiment - current_sentiment.score
                      A positive delta means sentiment has dropped since entry.
      SHORT position: delta = current_sentiment.score - entry_sentiment
                      A positive delta means sentiment has risen against the short.
    Absolute threshold comparisons are applied to this signed directional value.
    """
    soft_threshold = cfg.sentiment.soft_exit_delta_threshold
    strong_threshold = cfg.sentiment.strong_exit_delta_threshold
    confidence_min = cfg.sentiment.exit_confidence_min
    strong_confidence_min = cfg.sentiment.strong_exit_confidence_min

    for symbol, position in list(positions.items()):
        try:
            entry_sentiment = float(position.opening_compound)

            # Always fetch fresh news and force a real AI rescore.
            news_items = adapter.get_news(symbol, limit=10)
            current_sentiment = sentiment_module.force_rescore(symbol, news_items)
            current_confidence = float(current_sentiment.confidence)
            raw_discrete = int(current_sentiment.raw_discrete)

            # Change 1b: directional delta — only adverse shifts produce a
            # positive delta that can breach the exit thresholds.
            if position.side == "long":
                delta = entry_sentiment - current_sentiment.score
            else:
                delta = current_sentiment.score - entry_sentiment

            # ── Exit decision ─────────────────────────────────────────────────
            closing = False
            close_reason = ""

            # Tier 0: Hard exit — chaos / utterly unstable (raw_discrete == -2)
            if raw_discrete == -2:
                closing = True
                close_reason = (
                    f"raw_discrete=-2 chaos — utterly unstable; "
                    f"chaos cooldown timer applied."
                )

            # Tier 1: Strong exit — large delta with moderate confidence
            elif delta > strong_threshold and current_confidence > strong_confidence_min:
                closing = True
                close_reason = (
                    f"STRONG sentiment exit: "
                    f"Δ={delta:+.3f} > {strong_threshold} "
                    f"(entry={entry_sentiment:.3f} → current={current_sentiment.score:.3f}) "
                    f"against {position.side} position; "
                    f"confidence={current_confidence:.2f} > {strong_confidence_min}"
                )

            # Tier 2: Soft exit — moderate delta with higher confidence bar
            elif delta > soft_threshold and current_confidence > confidence_min:
                closing = True
                close_reason = (
                    f"SOFT sentiment exit: "
                    f"Δ={delta:+.3f} > {soft_threshold} "
                    f"(entry={entry_sentiment:.3f} → current={current_sentiment.score:.3f}) "
                    f"against {position.side} position; "
                    f"confidence={current_confidence:.2f} > {confidence_min}"
                )

            # Use the active threshold for the log display.
            display_threshold = strong_threshold if not closing or raw_discrete == -2 else (
                strong_threshold if delta > strong_threshold else soft_threshold
            )

            log_sentiment_position_check(
                position=position,
                entry_compound=entry_sentiment,
                current_sentiment=current_sentiment,
                delta=delta,
                delta_threshold=display_threshold,
                confidence_min=confidence_min,
                closing=closing,
                close_reason=close_reason,
                env_mode=cfg.env_mode,
            )

            if closing:
                executor.close_position_due_to_sentiment(
                    position=position,
                    sentiment=current_sentiment,
                    reason=close_reason,
                )

        except Exception as exc:
            logger.error(
                f"SentimentExit {symbol}: unexpected error during exit check: {exc}"
            )


# ── Main loop ──────────────────────────────────────────────────────────────────

def main() -> None:
    setup_logging()
    cfg = load_config()
    setup_logging(cfg.env_mode)
    log_environment_switch(cfg.env_mode, user="manual_start")

    adapter           = AlpacaAdapter(cfg.env_mode)
    sentiment         = SentimentModule()
    signal_engine     = SignalEngine(adapter, sentiment, cfg.technical)
    risk_engine       = RiskEngine(cfg.risk_limits, cfg.sentiment, cfg.instruments)
    pm                = PositionManager(adapter)
    executor          = OrderExecutor(adapter, cfg.env_mode, cfg.live_trading_enabled, cfg.execution)
    kill_switch       = KillSwitch(cfg.risk_limits)
    portfolio_builder = PortfolioBuilder(cfg, adapter, sentiment, signal_engine, risk_engine)

    # Registry: symbol -> sentiment_score recorded at entry time.
    # Change 1a: stores proposed.sentiment_score (compound sentiment float) —
    # NOT proposed.signal_score (technical composite). The exit delta check
    # subtracts this from current sentiment.score; mixing a technical score here
    # produced a semantically invalid cross-space comparison.
    # Persisted to equity_state.json so it survives bot restarts.
    _opening_compounds: Dict[str, float] = _load_opening_compounds()

    # Improvement D: initialise adaptive sleep interval before the loop.
    # Starts at 600s (the neutral-band default); hysteresis prevents oscillation.
    _rescore_interval: int = 600

    while True:
        acct        = adapter.get_account()
        positions   = pm.get_positions(opening_compounds=_opening_compounds)
        snapshot    = get_equity_snapshot_from_account(acct, positions)
        market_open = adapter.get_market_open()
        log_equity_snapshot(snapshot, market_open=market_open)

        ks_state = kill_switch.check(snapshot)
        log_kill_switch_state(ks_state)
        if ks_state.halted:
            time.sleep(60)
            continue

        # ── STEP 1: SENTIMENT CHECK ON ALL OPEN POSITIONS ───────────────────
        if positions:
            _check_and_exit_on_sentiment(
                positions=positions,
                adapter=adapter,
                sentiment_module=sentiment,
                executor=executor,
                cfg=cfg,
            )
            # Refresh positions after potential closes.
            positions = pm.get_positions(opening_compounds=_opening_compounds)
            snapshot  = get_equity_snapshot_from_account(acct, positions)

            # Purge _opening_compounds for symbols no longer open, then persist.
            for sym in list(_opening_compounds.keys()):
                if sym not in positions:
                    del _opening_compounds[sym]
            _persist_opening_compounds(_opening_compounds)

        # ── STEP 2: EXPOSURE / POSITION-COUNT GUARD ─────────────────────────
        exposure_cap_notional = snapshot.equity * cfg.risk_limits.gross_exposure_cap_pct
        if (
            snapshot.gross_exposure >= exposure_cap_notional
            or len(positions) >= cfg.risk_limits.max_open_positions
        ):
            time.sleep(60)
            continue

        # ── *** ADD THIS HERE *** ────────────────────────────────────────────
        # Uncomment to gate new entries on market hours:
        # if not market_open:
        #     logger.info("Market closed — skipping portfolio build and new entries.")
        #     time.sleep(60)
        #     continue

        # ── STEP 3: BUILD AND EXECUTE NEW TRADES ────────────────────────────
        open_orders     = adapter.list_orders(status="open")
        proposed_trades = portfolio_builder.build_portfolio(snapshot, positions, open_orders)

        log_portfolio_overview(proposed_trades, cfg.env_mode)

        for proposed in proposed_trades:
            order = executor.execute_proposed_trade(proposed)
            if order is not None and proposed.rejected_reason is None and proposed.qty > 0:
                # Change 1a: record entry-time SENTIMENT score (proposed.sentiment_score)
                # as the opening compound baseline — NOT proposed.signal_score.
                _opening_compounds[proposed.symbol] = proposed.sentiment_score
                # Persist immediately so a crash/restart doesn't lose the entry record.
                _persist_opening_compounds(_opening_compounds)

        # ── STEP 4: ADAPTIVE SLEEP WITH HYSTERESIS ──────────────────────────
        # Change 5 / Improvement D: sleep duration is driven by the highest
        # |sentiment.score| across all currently open positions. High-conviction
        # positions rescore every 120s; neutral portfolios wait up to 900s,
        # reducing API cost. Hysteresis prevents rapid interval oscillation when
        # max_abs_s hovers near a boundary threshold.
        _max_abs_s = max(
            (
                abs(sentiment.get_cached_sentiment(sym).score)
                for sym in positions
                if sentiment.get_cached_sentiment(sym) is not None
            ),
            default=0.0,
        )
        # Improvement D: use hysteresis guard instead of bare adaptive call.
        _rescore_interval = sentiment.adaptive_rescore_interval_hysteresis(
            _max_abs_s, _rescore_interval
        )
        time.sleep(_rescore_interval)


if __name__ == "__main__":
    main()

-----------

-----------
monitoring\__init__.py

-----------

-----------
monitoring\kill_switch.py
# CHANGES:
# - No functional changes from baseline.
# - KillSwitchState dataclass and KillSwitch.check() are fully typed.
# - Integrates with EquitySnapshot fields daily_loss_pct and drawdown_pct
#   already computed by get_equity_snapshot_from_account() in main.py.

import logging
from dataclasses import dataclass

from core.risk_engine import EquitySnapshot
from config.config import RiskLimits

logger = logging.getLogger("tradebot")


@dataclass
class KillSwitchState:
    """
    Result of a kill-switch evaluation.

    halted : bool
        True if trading should be suspended this loop iteration.
    reason : str
        Human-readable reason for the halt, or empty string if not halted.
    daily_loss_pct : float
        Observed daily P&L percentage (negative = loss).
    drawdown_pct : float
        Observed drawdown from high-watermark (negative = drawdown).
    """
    halted: bool
    reason: str
    daily_loss_pct: float
    drawdown_pct: float


class KillSwitch:
    """
    Hard-halt mechanism that suspends new trade entry when either:
      - The daily P&L loss exceeds daily_loss_limit_pct of start-of-day equity, OR
      - The portfolio drawdown from high-watermark exceeds max_drawdown_pct.

    Does NOT close existing positions — that is the responsibility of the
    sentiment-exit layer and the broker's bracket/stop orders.

    Thresholds are sourced directly from RiskLimits to stay in sync with
    RiskEngine.pre_trade_checks() guard logic.
    """

    def __init__(self, risk_limits: RiskLimits) -> None:
        self.limits = risk_limits

    def check(self, snapshot: EquitySnapshot) -> KillSwitchState:
        """
        Evaluate kill-switch conditions against the current equity snapshot.

        Parameters
        ----------
        snapshot : EquitySnapshot
            Current account state as computed by get_equity_snapshot_from_account().

        Returns
        -------
        KillSwitchState
        """
        daily_loss_pct = snapshot.daily_loss_pct
        drawdown_pct = snapshot.drawdown_pct

        # Daily loss breach
        if daily_loss_pct <= -self.limits.daily_loss_limit_pct:
            reason = (
                f"KILL SWITCH: daily loss {daily_loss_pct:.2%} breached limit "
                f"-{self.limits.daily_loss_limit_pct:.2%}. "
                f"Halting new entries for this cycle."
            )
            logger.warning(reason)
            return KillSwitchState(
                halted=True,
                reason=reason,
                daily_loss_pct=daily_loss_pct,
                drawdown_pct=drawdown_pct,
            )

        # Drawdown breach
        if drawdown_pct <= -self.limits.max_drawdown_pct:
            reason = (
                f"KILL SWITCH: drawdown {drawdown_pct:.2%} breached limit "
                f"-{self.limits.max_drawdown_pct:.2%}. "
                f"Halting new entries for this cycle."
            )
            logger.warning(reason)
            return KillSwitchState(
                halted=True,
                reason=reason,
                daily_loss_pct=daily_loss_pct,
                drawdown_pct=drawdown_pct,
            )

        return KillSwitchState(
            halted=False,
            reason="",
            daily_loss_pct=daily_loss_pct,
            drawdown_pct=drawdown_pct,
        )

-----------

-----------
monitoring\monitor.py
# CHANGES:
# - No functional changes from baseline.
# - Full file reproduced verbatim to restore all ANSI colour formatting,
#   separator helpers, italicize_technical(), sentiment_score_fragment(),
#   nextlinecolor cycling, and all log_* functions that were present in the
#   original 400-line version.

import logging
import threading
from datetime import datetime
from typing import List, Optional

from core.risk_engine import EquitySnapshot, ProposedTrade, PositionInfo
from core.sentiment import SentimentResult
from config.config import ENV_MODE

logger = logging.getLogger("tradebot")

# ── ANSI colour constants ──────────────────────────────────────────────────────

RESET         = "\033[0m"
BOLD          = "\033[1m"
ITALIC        = "\033[3m"
DEEPBLUE      = "\033[38;5;27m"
BRIGHTPURPLE  = "\033[38;5;135m"
SIGNALGREEN   = "\033[38;5;46m"
SIGNALRED     = "\033[38;5;196m"
MARKETOPEN    = "\033[38;5;82m"
MARKETCLOSED  = "\033[38;5;214m"

# Colour palette cycled per log block so adjacent blocks are visually distinct.
_LINE_COLOURS = [
    "\033[38;5;33m",   # steel blue
    "\033[38;5;39m",   # sky blue
    "\033[38;5;44m",   # cyan-ish
    "\033[38;5;75m",   # light blue
    "\033[38;5;111m",  # periwinkle
]
_colour_index = 0
_colour_lock  = threading.Lock()


def nextlinecolor() -> str:
    """Return the next colour from the cycling palette (thread-safe)."""
    global _colour_index
    with _colour_lock:
        c = _LINE_COLOURS[_colour_index % len(_LINE_COLOURS)]
        _colour_index += 1
    return c


# ── Separator helpers ─────────────────────────────────────────────────────────

def _thick(width: int = 80) -> str:
    return "═" * width

def _thin(width: int = 80) -> str:
    return "─" * width

def thick(width: int = 80) -> str:
    return _thick(width)

def thin(width: int = 80) -> str:
    return _thin(width)

def separatorline(width: int = 80) -> str:
    return "-" * width


# ── Text helpers ──────────────────────────────────────────────────────────────

def italicize_technical(text: str) -> str:
    """Wrap text in ANSI italic escape codes."""
    return f"{ITALIC}{text}{RESET}"


def sentiment_score_fragment(score: float, lc: str) -> str:
    """
    Return a colour-coded sentiment score string.
      score >  0.5  → green
      score < -0.5  → red
      otherwise     → line colour (lc)
    """
    if score > 0.5:
        sc_color = SIGNALGREEN
    elif score < -0.5:
        sc_color = SIGNALRED
    else:
        sc_color = lc
    return f"{sc_color}{score:.3f}{lc}"


# ── Logging setup ─────────────────────────────────────────────────────────────

def setup_logging(env_mode: str = "PAPER") -> None:
    """Configure root logger. Call once at startup."""
    import sys
    level = logging.DEBUG if env_mode == "PAPER" else logging.INFO
    fmt     = "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
    datefmt = "%Y-%m-%d %H:%M:%S"
    root = logging.getLogger()
    if root.handlers:
        root.handlers.clear()
    handler = logging.StreamHandler(sys.stdout)
    handler.setFormatter(logging.Formatter(fmt, datefmt=datefmt))
    root.addHandler(handler)
    root.setLevel(level)


def log_environment_switch(env_mode: str, user: str = "") -> None:
    tag = f" (triggered by: {user})" if user else ""
    lc  = nextlinecolor()
    logger.info(f"{lc}{_thick()}{RESET}")
    logger.info(f"{lc}ENVIRONMENT: {env_mode}{tag}{RESET}")
    logger.info(f"{lc}{_thick()}{RESET}")


# ── Instrument report (called by SignalEngine for every symbol) ───────────────

def log_instrument_report(
    symbol: str,
    signal_score: float,
    sentiment: SentimentResult,
    momentum_score: float,
    mean_reversion_score: float,
    price_action_score: float,
    env_mode: str = "PAPER",
) -> None:
    """
    Unified per-symbol evaluation block emitted by SignalEngine for every
    symbol it processes — both trade (buy/sell) and skip paths.
    Renders:
      - Signal decomposition: momentum, mean-reversion, price-action, composite
      - Sentiment block: score, discrete, confidence, ndocuments, explanation
    Replaces the two deprecated shims log_signal_score and log_sentiment_for_symbol
    that were previously called separately from signals.py.
    """
    lc  = nextlinecolor()
    W   = 80
    thn = f"{lc}{_thin(W)}{RESET}"

    # Composite signal colour
    if signal_score > 0:
        sig_color = SIGNALGREEN
    elif signal_score < 0:
        sig_color = SIGNALRED
    else:
        sig_color = lc

    # Sentiment score colour
    sc = sentiment.score
    if sc > 0.5:
        sc_color = SIGNALGREEN
    elif sc < -0.5:
        sc_color = SIGNALRED
    else:
        sc_color = lc

    symbol_str = f"{BRIGHTPURPLE}{symbol}{lc}"
    sig_str    = f"{sig_color}{signal_score:.3f}{lc}"
    sc_str     = f"{sc_color}{sc:.3f}{lc}"

    expl_raw = (sentiment.explanation or "").replace("\n", " ").strip()
    expl_fmt = italicize_technical(expl_raw)

    logger.info(thn)
    logger.info(
        f"{lc} {env_mode} {DEEPBLUE}SIGNAL{lc} "
        f"{symbol_str}  composite={sig_str}{RESET}"
    )
    logger.info(
        f"{lc}   momentum={momentum_score:.3f}  "
        f"meanrev={mean_reversion_score:.3f}  "
        f"priceaction={price_action_score:.3f}{RESET}"
    )
    logger.info(
        f"{lc}   sentiment={sc_str}  "
        f"discrete={sentiment.raw_discrete}  "
        f"conf={sentiment.confidence:.2f}  "
        f"docs={sentiment.ndocuments}{RESET}"
    )
    if expl_fmt:
        logger.info(f"{lc}   {expl_fmt}{RESET}")
    logger.info(thn)


# ── Proposed trade log ────────────────────────────────────────────────────────

def log_proposed_trade(trade: ProposedTrade, env_mode: str = "PAPER") -> None:
    """
    Emit a richly formatted block for a ProposedTrade — accepted or rejected.
    Unexpected trade.side emits logger.warning instead of silently producing
    an empty action tag.
    """
    lc         = nextlinecolor()
    line_color = lc
    sep        = f"{line_color}{separatorline()}{RESET}"

    sentiment_part = sentiment_score_fragment(trade.sentiment_score, line_color)

    if trade.rejected_reason is None and trade.qty > 0:
        if trade.side == "buy":
            action_tag = f" {SIGNALGREEN}BUY{line_color}"
        elif trade.side == "sell":
            action_tag = f" {SIGNALRED}SELL{line_color}"
        else:
            logger.warning(
                f"log_proposed_trade: unexpected side={trade.side} "
                f"for {trade.symbol}; expected 'buy' or 'sell'."
            )
            action_tag = f" {trade.side.upper()}"
    else:
        action_tag = ""

    notional    = trade.qty * trade.entry_price
    symbol_part = f"{BRIGHTPURPLE}{trade.symbol}{line_color}"
    sig_part    = f"{BRIGHTPURPLE}{trade.signal_score:.3f}{line_color}"

    msg = (
        f"{datetime.utcnow().isoformat()}Z  {env_mode}  ProposedTrade  "
        f"symbol={symbol_part}  {trade.side}  "
        f"qty={trade.qty:.4f}  notional={notional:.2f}  "
        f"entry={trade.entry_price:.4f}  stop={trade.stop_price:.4f}  tp={trade.take_profit_price:.4f}  "
        f"riskamt={trade.risk_amount:.2f}  riskpct={trade.risk_pct_of_equity:.4f}  "
        f"sentiment={sentiment_part}  scale={trade.sentiment_scale:.3f}  "
        f"rejected={trade.rejected_reason}  "
        f"{action_tag}{sig_part}"
    )
    logger.info(f"{line_color}{msg}{RESET}")
    logger.info(sep)


# ── Legacy shim: log_sentiment_for_symbol ────────────────────────────────────

def log_sentiment_for_symbol(
    symbol: str,
    sentiment: SentimentResult,
    env_mode: str,
) -> None:
    """
    Legacy shim retained because main.py imports this function by name.
    Delegates to log_instrument_report with zeroed technical scores so any
    remaining callers continue to work without error.
    """
    log_instrument_report(
        symbol=symbol,
        signal_score=0.0,
        sentiment=sentiment,
        momentum_score=0.0,
        mean_reversion_score=0.0,
        price_action_score=0.0,
        env_mode=env_mode,
    )


# ── Portfolio overview ────────────────────────────────────────────────────────

def log_portfolio_overview(trades: List[ProposedTrade], env_mode: str = "PAPER") -> None:
    lc  = nextlinecolor()
    sep = f"{lc}{separatorline()}{RESET}"

    logger.info(sep)

    if not trades:
        header = f"{datetime.utcnow().isoformat()}Z  {env_mode}  PORTFOLIO OVERVIEW"
        logger.info(f"{DEEPBLUE}{header}{RESET}")
        logger.info(f"{DEEPBLUE}No new trades selected in this cycle.{RESET}")
        logger.info(sep)
        return

    header = f"{datetime.utcnow().isoformat()}Z  {env_mode}  PORTFOLIO OVERVIEW"
    logger.info(f"{lc}{header}{RESET}")

    for t in trades:
        notional    = t.qty * t.entry_price
        symbol_part = f"{BRIGHTPURPLE}{t.symbol}{lc}"
        sig_str     = f"{BRIGHTPURPLE}{t.signal_score:.3f}{lc}"
        msg = (
            f"  symbol={symbol_part}  side={t.side}  "
            f"qty={t.qty:.4f}  notional={notional:.2f}  "
            f"signalscore={sig_str}  rejected={t.rejected_reason}"
        )
        logger.info(f"{lc}{msg}{RESET}")

    logger.info(sep)


# ── Equity snapshot ───────────────────────────────────────────────────────────

def log_equity_snapshot(
    snapshot: EquitySnapshot,
    market_open: bool = False,
) -> None:
    lc = nextlinecolor()

    market_tag = (
        f"{MARKETOPEN}MARKET OPEN{lc}"
        if market_open
        else f"{MARKETCLOSED}MARKET CLOSED{lc}"
    )
    daily_color = SIGNALRED  if snapshot.daily_loss_pct < 0 else SIGNALGREEN
    dd_color    = SIGNALRED  if snapshot.drawdown_pct   < 0 else SIGNALGREEN

    msg = (
        f"{datetime.utcnow().isoformat()}Z  EquitySnapshot  "
        f"equity={snapshot.equity:.2f}  cash={snapshot.cash:.2f}  "
        f"portfoliovalue={snapshot.portfolio_value:.2f}  "
        f"grossexp={snapshot.gross_exposure:.2f}  "
        f"dailyloss={daily_color}{snapshot.daily_loss_pct:.3%}{lc}  "
        f"drawdown={dd_color}{snapshot.drawdown_pct:.3%}{lc}  "
        f"{market_tag}"
    )
    logger.info(f"{lc}{msg}{RESET}")
    logger.info(f"{lc}{separatorline()}{RESET}")


# ── Kill switch ───────────────────────────────────────────────────────────────

def log_kill_switch_state(ks_state) -> None:
    """
    Log the result of each kill-switch evaluation.
    ks_state is a KillSwitchState dataclass from monitoring/kill_switch.py.
    """
    if ks_state.halted:
        logger.warning(
            f"{SIGNALRED}KILL SWITCH ACTIVE{RESET}  {ks_state.reason}  "
            f"daily_pnl={ks_state.daily_loss_pct:+.2%}  "
            f"drawdown={ks_state.drawdown_pct:+.2%}"
        )
    else:
        logger.debug(
            f"Kill switch OK  "
            f"daily_pnl={ks_state.daily_loss_pct:+.2%}  "
            f"drawdown={ks_state.drawdown_pct:+.2%}"
        )


# ── Sentiment position check (per open position, per rescore cycle) ───────────

def log_sentiment_position_check(
    position: PositionInfo,
    entry_compound: float,
    current_sentiment: SentimentResult,
    delta: float,
    delta_threshold: float,
    confidence_min: float,
    closing: bool,
    close_reason: str,
    env_mode: str = "PAPER",
    stop_price: Optional[float] = None,
    take_profit_price: Optional[float] = None,
) -> None:
    """
    Emit a detailed per-position sentiment-check block each rescore cycle.
    Chaos exit (raw_discrete == -2) also marks triggered_tag and delta_color
    so the delta row is visually consistent with the Verdict.
    """
    lc  = nextlinecolor()
    W   = 80
    thk = f"{lc}{_thick(W)}{RESET}"
    thn = f"{lc}{_thin(W)}{RESET}"

    rd = current_sentiment.raw_discrete

    symbol_str  = f"{BRIGHTPURPLE}{position.symbol}{lc}"
    side_str    = (
        f"{SIGNALGREEN}{position.side.upper()}{lc}"
        if position.side == "long"
        else f"{SIGNALRED}{position.side.upper()}{lc}"
    )
    notional_val = abs(position.qty * position.market_price)
    header_body  = (
        f" {DEEPBLUE}SENTIMENT CHECK{lc}  "
        f"{symbol_str}  {side_str}  "
        f"qty={position.qty:.4f}  notional={notional_val:.2f}"
    )

    # Sentiment score colour
    sc       = current_sentiment.score
    sc_color = SIGNALGREEN if sc > 0.5 else SIGNALRED if sc < -0.5 else lc
    sc_str   = f"{sc_color}{sc:.3f}{lc}"

    # Entry compound colour
    ec_color = SIGNALGREEN if entry_compound > 0 else SIGNALRED
    ec_str   = f"{ec_color}{entry_compound:.3f}{lc}"

    sl_str = f"{stop_price:.2f}"       if stop_price       is not None else "N/A"
    tp_str = f"{take_profit_price:.2f}" if take_profit_price is not None else "N/A"

    meta_row = (
        f" Current Sentiment={sc_str}  "
        f"Opening Compound={ec_str}  "
        f"Stop Loss={sl_str}  Take Profit={tp_str}"
    )

    # Delta colour — red if adverse (closing), green if stable
    delta_color = SIGNALRED if closing else SIGNALGREEN
    chaos_exit  = (rd == -2)

    if chaos_exit:
        triggered_tag = f"  {SIGNALRED}[CHAOS raw_discrete=-2]{lc}"
        delta_color   = SIGNALRED
    elif closing:
        triggered_tag = f"  {SIGNALRED}[THRESHOLD BREACHED]{lc}"
    else:
        triggered_tag = ""

    delta_str = (
        f" Δ={delta_color}{delta:+.3f}{lc}  "
        f"threshold={delta_threshold:.3f}  "
        f"conf={current_sentiment.confidence:.2f}  "
        f"conf_min={confidence_min:.2f}  "
        f"discrete={rd}"
        f"{triggered_tag}"
    )

    expl_raw = (current_sentiment.explanation or "").replace("\n", " ").strip()
    expl_fmt = italicize_technical(expl_raw)

    if closing:
        if chaos_exit:
            verdict_detail = f"{SIGNALRED} CLOSING  raw_discrete=-2  CHAOS absolute exit{lc}"
        else:
            verdict_detail = (
                f"{SIGNALRED} CLOSING  sentiment shift "
                f"Δ={delta:.3f} > threshold {delta_threshold:.3f}{lc}"
            )
    else:
        verdict_detail = f"{SIGNALGREEN} HOLDING  no exit condition met{lc}"

    logger.info(thk)
    logger.info(f"{lc}{header_body}{RESET}")
    logger.info(thk)
    logger.info(f"{lc}{meta_row}{RESET}")
    logger.info(thn)
    logger.info(f"")
    logger.info(f"{lc} Entry compound    {ec_str}{RESET}")
    logger.info(f"")
    logger.info(f"")
    logger.info(f"{lc} {delta_str}{RESET}")
    logger.info(f"")
    logger.info(f"{lc} Explanation  {expl_fmt}{RESET}")
    logger.info(f"")
    logger.info(f"{lc} docs={current_sentiment.ndocuments}{RESET}")
    logger.info(thn)
    logger.info(f"")
    logger.info(f"{lc} Verdict  {verdict_detail}{RESET}")
    logger.info(f"")
    logger.info(thk)


# ── Sentiment close decision (called by OrderExecutor) ───────────────────────

def log_sentiment_close_decision(
    symbol: str,
    side: str,
    qty: float,
    sentiment_score: float,
    confidence: float,
    explanation: str,
    env_mode: str,
    reason: str,
) -> None:
    lc        = nextlinecolor()
    score_frag = sentiment_score_fragment(sentiment_score, lc)

    expl_raw = (explanation or "").replace("\n", " ").strip()
    expl_fmt = italicize_technical(expl_raw)

    force_msg   = f"{SIGNALRED}FORCE-CLOSED DUE TO BAD SENTIMENT{lc}"
    symbol_part = f"{BRIGHTPURPLE}{symbol}{lc}"

    msg = (
        f"{datetime.utcnow().isoformat()}Z  {env_mode}  SentimentExit  "
        f"symbol={symbol_part}  side={side}  qty={qty:.4f}  "
        f"{score_frag}  conf={confidence:.2f}  "
        f"reason_for_exit={reason}  "
        f"{force_msg}  "
        f"{expl_fmt}"
    )
    logger.warning(f"{lc}{msg}{RESET}")
    logger.info(f"{lc}{separatorline()}{RESET}")

-----------

-----------
requirements.txt
alpaca-trade-api>=3.0.0
PyYAML>=6.0
pytz>=2024.1

-----------

-----------
tests\__init__.py

-----------

